
jgrewe
1:54 PM
joined #odml. Also, @achilleas joined.

achilleas
2:46 PM
Weeeeell
2:46
Here I was trying to create the odML channel
2:46
and it's already here

jgrewe
4:46 PM
sorry

rickskyy
5:53 PM
joined #odml by invitation from @achilleas

jgrewe
6:01 PM
ah
6:01
g’day

rickskyy
6:18 PM
somewhat pessimistic ))"We have problems on multiple levels:
- we are in the process of refactoring odML.
- we have no proper overview of which odML versions are out there and no good understanding of how they are currently used.
    - don't have even proper example odML files from any of the users!
- we have no one who actually is proficient in RDF, knows how the class system works and how to best design it
    - to specify: to which degree should we use RDF terms that are already there, or should we use just our own defined RDF terms.
- we have no good idea, how the people from the CRCNS actually work with RDF and which format would be good for them
    - how would they like to search the data.
    - which RDF terminologies are they using, etc.
    - if they use validators for RDF graphs"

jgrewe
6:28 PM
Indeed that sounds pessimistic
6:28
:smirk:

jgrewe
7:15 PM
But methinks it is not that bad, or the other way round, we simply do what we like

dumdribille
11:26 AM
joined #odml

dumdribille
11:27 AM
@rickskyy jan and me are just re-organizing the odml document
11:28
adding examples for the more tricky parts
11:28
and removing odml terms that should not be supported any longer
11:28
feel free to join in of course! :slightly_smiling_face:

jgrewe
11:28 AM
@rickskyy, please visit gin.g-node.org and register there, then we can add you to a repository containing some example files
11:29
will be extending that

rickskyy
11:38 AM
registered as rickskyy
11:39
https://web.gin.g-node.org/rickskyy
web.gin.g-node.org
rickskyy (Yaroslav Shalivskyy)
rickskyy has 0 followers and is following 0 people.

rickskyy
11:49 AM
the graph image is nice)

dumdribille
11:53 AM
merci
11:53
the graph will still change today though :wink:
11:54
with the changes @jgrewe an and me discussed just now
11:54
but everything will become easier which is nice...

jgrewe
11:57 AM
@cgars could you add yaroslav to the gin/odmlFiles repo

cgars
11:57 AM
joined #odml by invitation from @jgrewe

rickskyy
11:57 AM
yeah it is easier to go from this point comparing to yesterday version)

dumdribille
3:00 PM
k, I updated the document some more and added the new and improved first version draft graph!

dumdribille
5:44 PM
c:

rickskyy
8:21 PM
great, thanks) (edited)
rickskyy
11:19 AM

<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet  type="text/xsl" href="odmlTerms.xsl"?>

<?xml-stylesheet  type="text/xsl" href="odml.xsl"?>

<odML version="1.1">

  <id>"1"</id>

rickskyy
11:21 AM
Does this look ok? There will be uuids as ids, current id strings are just for example

dumdribille
12:13 PM
oh, cool!
12:14
we have a meeting next
12:14
I'll get back to you in the afternoon when I had time to properly appreciate it :wink:

rickskyy
12:49 PM
frankly there is nothing to really appreciate yet))

dumdribille
2:51 PM
From my point of view the file looks good, except for the type in property which should be dtype instead.
2:52
I think thats to distinguish between the type of a section for searching purposes and the dtype which actually describes the datatype of the value.

jgrewe
2:53 PM
uh, actually I am not sure, if dtype isn’t mapped to type in the xml writer

dumdribille
2:53 PM
but that has been changed in the latest version of the odml->rdf document I think :wink:
2:53
ah, ok!

jgrewe
2:55 PM
but in the rdf export I agree
2:55
should be dtype there
2:55
regarding the id strings, I guess there is not reason to have the with quotation marks
rickskyy

4:01 PM
yeah, there won't be quotation marks (edited)

rickskyy
4:11 PM

<rdf:RDF xml:lang="en"

         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"

         xmlns:odml="http://g-node/odml#"

         xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#">

rickskyy
4:11 PM

<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet  type="text/xsl" href="odmlTerms.xsl"?>

<?xml-stylesheet  type="text/xsl" href="odml.xsl"?>

<odML version="1.1">

  <id>aaa</id>

rickskyy
4:11 PM
so here is the example of an rdf and odml ( odml is mostly the same as I sent earlier)
4:13
rdf is validated by this tool from w3
https://www.w3.org/RDF/Validator/
4:14
I like the validator because it automatically builds graph and generates errors if smth goes wrong with the rdf model (edited)

rickskyy
4:16 PM
The graph generated

rickskyy
4:18 PM
how does it look? I use this example as the starting point for the converter (edited)

dumdribille
4:18 PM
I just glanced over everything and it looks really good!
4:19
I got some comments, but I think I will only manage to properly think them through later in the afternoon. :wink:
4:20
the validator seems like  a really helpful tool!

rickskyy
4:21 PM
the only problem is that it generates error if I use uuids which start with a digit
Error: {W108} Not an XML Name: '05e14adf-1ca2-4b2d-984d-6c84814a84de'[Line = 6, Column = 72] (edited)
4:23
but for simple test examples it is quite good
4:27
Also I write some logs about my work in the doc below. Happy to see your comments or feedback there.
https://docs.google.com/document/d/1EZu6g8TG2ZzoJaXNaTeMDFY5yQTJh1RRm6vf675bMsM/edit?usp=sharing

dumdribille
4:29 PM
perfect, thx!
rickskyy
4:32 PM
:blush:
rickskyy
7:08 PM
As you saw I simply duplicated the attributes which relate to the rdfs schema.
Like:
       <odml:definition>Information on the crew</odml:definition>
       <rdfs:comment>Information on the crew</rdfs:comment>It seems to me quite redundant. What do you think about the idea of mapping between such cases while converting to both sides? So the rdf doc would have only comment and odml definition respectively. (edited)
rickskyy
7:35 PM

<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF

   xmlns:ns1="http://g-node/odml#"

   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"

   xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"

This is the example file generated with rdflib without duplicated properties.

dumdribille
7:59 PM
finally had some time to look everything over!
7:59
so far it looks good!
8:01
one of the comments I wanted to make when I saw the first draft you already addressed: (edited)
8:02
with respect to the duplicated properties
8:02
Its either odml:name OR RDFS:label and equivalent odml:definition OR RDFS:comment. I just added the alternatives in respect to the case we want to move to the direction to use less custom terms and more already existing RDF terms. (edited)
8:02
for now I think we should implement just the terms in the RDF column.
8:02
The same is true for si:units - use odml:unit for now and if there is time explore if we could use the existing si:unit vocabulary.
8:02
in the concept document, everything in the "RDF alternative" column is supposed to be either an additional comment or an alternative term to the main rdf term. Every RDF:label or RDF:comment
8:03
I think with respect to the other comments, I will collect them and comment in a couple of days, since I am sure, that many of them you have already on your mind, but had no time to address yet. :wink:

rickskyy
2:05 PM
Hello everyone,Just uploaded the first version of a converter:https://github.com/rickskyy/python-odml/blob/rdf-converter/converter/tools/rdf_converter.pyNow working towards adding links and includes in sections.So far have some questions:1) What are specific data types can be used for objects in a triple, in particular, for values of a property, to specify for the xsd type schema? First one I saw and came with was date so I can explicitly specify it, guess there are more.2) Should the bag be created in all cases (even for one value)?
GitHub
rickskyy/python-odml
python-odml - odML libraries and editor

achilleas
2:06 PM
I've been falling behind on this so I'll have to check what you guys were talking about before having a look.

dumdribille
2:10 PM
hi!

dumdribille
3:14 PM
thx for the code!
3:14
ad 2) I would say use a bag in every case even if there is only one value

dumdribille
3:22 PM
ad 1) I am not sure how we should add data types directly to values , since this is handled via property.dtype. The type defined there applies to all values in the bag. Maybe if dtype is a basic datatype, then add the corresponding datatype, otherwise add xsd:string.
3:23
we were also thinking about how to best do code reviews with the current project setup
3:24
it would probably be best, if we create a dev-odml-rdf branch on G-Node/python-odml and @rickskyy can then do pull requests towards this branch
3:24
which we then can properly review, comment, issurize and everything

achilleas
3:25 PM
odml-rdf-dev would be better, surely

rickskyy
6:34 PM
thank you for the response)


10.07.2017
rickskyy
11:59 AM
Some questions to discuss.
1) Should we use empty bag for None values.
2) How the terminology can be accessed/stored besides the url in the document.
3) As I read references could be strings to some DB besides url. What do you think of adding a some kind of url validator to diversify such cases? Since different identifiers in rdflib are used (URIRef and Literal) it might be important.
4) Questions about link&include:
    a) Does inheritance work only for properties or other attributes as well?
    b) Should I manage some validation issues e.g. is link from the section to its subsection is considered as mistake?
    c) Are values of links' attributes just name of Sections in the current document? (edited)

dumdribille
1:08 PM
starting hangout :wink:

jgrewe
1:25 PM
There are situations in which a strict application of the rules about the hierarchical organization (see above) 
would lead to complicated and redundant structures. To avoid this odML Sections dene link, include, and reference 
elements which can be used to introduce relations that exist outside the hierarchical organization.
A link is used to refer to sections within the document and contains a path in the tree. Paths de ning the position 
in the tree are given by Section names, separated by slashes (“/”). Paths are absolute, i.e., they begin at the root 
of the tree. To illustrate the use of links, we consider a case in which a number of datasets have been recorded using a 
rather complex stimulus. The stimulus is repeated for each dataset, but each time a single stimulus parameter, e.g., 
the intensity, has been changed. It would be valid to provide the full stimulus description for each dataset 
individually but, obviously, this would be cumber- some and inef cient. Instead, one de nes the stimulus once 
within the document and then links to it for each dataset. The referring stimulus sections contain only the changes 
(i.e., the “intensity” properties). Links can only exist between sections of the same type and include all subsections and 
properties. Local information, given in the linking section, overrides items inherited from the linked Section.
The include element can be used to establish relations to sec- tions (same type) that are located in an external  le. 
Include entries can be either an URL or a path in the  le system (rela- tive or absolute). The URL is followed by a hash symbol (#) 
and the absolute path of the target Section. For example, a stimulus Section could contain an include element 
like “stimulus-metadata. xml#myStimulus.” This indicates that the stimulus information is provided in a stimulus-type section 
of the name “myStimulus” located in the “stimulus-metadata.xml”  le in the same folder in the  le system. Of course care 
has to be taken if the data is shared when local  les are referenced. As for the link element the locally provided 
information overrides the one given in the included section.
1:26
some information on links and includes

rickskyy
9:44 PM
Thanks Jan for the info. In general I understand the concept.
I guess BaseSection.merge does the linkage. I did not see that when I was writing questions and thought I should implement this merge myself.
Finally, in terms of the converter - the link is just a Literal string, and include is a string or a URIRef?

jgrewe
9:47 PM
could you verify that the merge actually does what is claims? That would be great
9:49
both link and include are basically strings. The includes are urls/uris in the ideal world. could also be just filenames and path within that file

rickskyy
9:56 PM
ok, I will check this


11.07.2017
dumdribille
10:28 AM
I just created the dev-odml-rdf branch on the G-Node/python-odml repository from current master
10:29
@rickskyy you can create pull requests against that branch from now on. :slightly_smiling_face:


dumdribille
5:14 PM
@rickskyy @jgrewe guys, I just added a Q&A section at the bottom of the "Exporting odML to RDF" google doc
5:14
but I am actually not very happy with this communication
5:16
I'd rather have these discussions on github either as issues or via a specific project
5:16
I guess if Yaroslav, you have questions, add them as issues and we discuss over there
5:17
then we can also easily go back and check if we are unsure about our reasons 3 months from now.
5:18
we could either use "[rdf] title" to distinguish these issues from other python-odml issues or we create a github project for it and tag the issues with it.
5:19
@rickskyy I have some comments and some additional assignments for this week.
5:19
should I post them here or add them to your day log google doc? I don't mind either :slightly_smiling_face:
5:21
@jgrewe @rickskyy maybe we could also agree one time during the week, where we are more or less available for half a day and chat about arisen questions
5:21
because right now it is more or less asynchronious all the time :wink:

dumdribille
5:27 PM
sucks a bit, that we all three sit in completely different locations :stuck_out_tongue:

jgrewe
5:30 PM
indeed, I agree with the github issues if there is some intense discussio required we can still switch to slack or hangout (edited)
5:32
I am basically offline for the next two days

dumdribille
5:33 PM
in general, when would be a good day for you to be available for chatting here?
5:33
on and off of course :wink:
5:34
just so @rickskyy and me know at that time its nice to hang out in the slackroom

jgrewe
5:34 PM
can’t say definitely, things keep changing faster than I like
5:34
:slightly_smiling_face:
5:34
i usually have it on all day

dumdribille
5:34 PM
thus is the life of a postdoc :stuck_out_tongue:

jgrewe
5:34 PM
hehe
5:36
maybe it is easier the other way round, Tuesday mornings is bad since we have seminars, I would also like to keep the Monday morning clear…
5:36
othewise I am mainly flexible

dumdribille
5:37 PM
that sounds like a good approach!
5:37
for me monday afternoon sucks because of meetings, friday afternoon because of frequent vienna travels
5:37
and the DB does not provide wireless on their part of the travel-leg

jgrewe
5:38 PM
fair enough :slightly_smiling_face: I considered ICE travel as a distraction-free time and now they have wireless … (edited)

dumdribille
5:39 PM
on the upper hand, it keeps the other passengers quiet :wink:
5:39
*upside actually


rickskyy
5:46 PM
hi everyone, sorry, was offline during the whole day. (edited)
5:47
about assignments, I think it's better to post them to google doc
5:48
I mostly open for any day and time for chatting, just let me know what is the best option for you so I can organize my time correctly
dumdribille
5:49 PM
no problemo :wink:
5:50
maybe we can aim for tuesday afternoon in general then
jgrewe
5:50 PM
fine with me
rickskyy
5:50 PM
that sounds good
5:52
@dumdribille check if you can edit the doc, I changed the sharing
here is the link: https://docs.google.com/document/d/1EZu6g8TG2ZzoJaXNaTeMDFY5yQTJh1RRm6vf675bMsM/edit?usp=sharing (edited)
dumdribille
5:53 PM
works!
5:55
most of the comments I just added aim towards the output rdf
5:56
to get our individually defined classes in there
5:56
and to create a schema that can be used for proper validation
5:57
I just need to figure out where to host the schema after we have it :wink:
rickskyy
5:58 PM
the schema is mostly defined in odml.format as _rdf_map
5:59
you mean schema file as namespace?
dumdribille
5:59 PM
indeed
6:00
sthg like thus
6:00
http://xmlns.com/foaf/spec/index.rdf
rickskyy
6:00 PM
I understand
dumdribille
6:00 PM
this then can be used to validate the resulting rdf file against
rickskyy
6:00 PM
i guess you can add a page on the g-node website (edited)
dumdribille
6:01 PM
yeah the final version should be found there eventually
6:02
but I think this one will still change quite heavily during development
6:02
I wonder whether it should reside in its own github repo or if we should add it to the python-odml repo for now
6:02
decisions descision
jgrewe
6:03 PM
go for it and just decide :slightly_smiling_face:
dumdribille
6:03 PM
or whether it should reside with the odml templates, since it touches a very similar topic
jgrewe
6:03 PM
For the moment I would vote for keeping everything in the same place
rickskyy
6:03 PM
I think it can stay in python-odml
6:04
2 votes for now for the staying at python-odml)
dumdribille
6:05 PM
sounds good :slightly_smiling_face:
6:05
maybe in the doc section of the converter for now then
rickskyy
6:07 PM
let's discuss the package structure than
6:09
smth like:
converter/
       doc/
             examples/
                  example.odml
                  example_generator.py
                  example_rdf.rdf
             schema_odml.rdf
       tools/
             rdf_converter.py
             rdf_json_converter.py
             other_converter.py (edited)
6:09
?
dumdribille
6:10 PM
looks good
rickskyy
6:10 PM
I thought all this would go to the odml.tools eventually
dumdribille
6:11 PM
plus converter/doc/schema_odml.rdf for the new and over time improving schema :wink:
jgrewe
6:12 PM
does it need the converter?
6:13
i mean the converter folder/package?
rickskyy
6:13 PM
I have same doubts
6:13
converter/tools can go nicely to odml/tools
6:14
with docs pretty the same (edited)
jgrewe
6:14 PM
yep
dumdribille
6:15 PM
true, since we develop against a different branch anyhow, we could already properly integrate the rdf converter
6:15
no objection here :slightly_smiling_face:
rickskyy
6:17 PM
so final decision to keep everything in the existing folders odml tools and docs?
6:17
good
6:17
there is a comment number 4 about xml vs turtle representation
dumdribille
6:18 PM
yeah, I like turtle
rickskyy
6:18 PM
the reason I was using xml to check if ids work right
dumdribille
6:18 PM
I'd actually support whichever format the user wants and rdflib provides
6:18
but for our examples i'd prefer turtle
6:18
its nice to read
6:19
aaah I see
rickskyy
6:19 PM
because I was changing some code in existing xmlparsers to keep them work correctly
6:19
turtles looks more human-readable
6:20
i vote for turtles for examples and documentation but yeah the user can choose what he/she wants
6:20
there is plenty of formats in rdflib and it's easy to switch between them (edited)
6:24
I propose to strikethrough the comments that we already discussed. What do you think?
dumdribille
6:24 PM
do it :slightly_smiling_face:
rickskyy
6:25 PM
what a bag I recall
6:25
hah
6:26
would we create it for none values?
dumdribille
6:26 PM
hm, let me quickly create a couple of issues and post my answers there to get us started with the issues :wink:
rickskyy
6:27 PM
ok
6:28
i prepare than a pool request
dumdribille
6:29 PM
cool!
6:32
ok, posted three example question / issues and my current answers to them
6:33
@jgrewe @rickskyy if you have any suggestions about the format, if you want to handle them differently or want to add a project to it, comment away :slightly_smiling_face:
rickskyy
6:39 PM
thanks it's a nice way to discuss questions) Looked through everything and agree with all points.
dumdribille
6:40 PM
cool! :slightly_smiling_face:
6:41
maybe we can come up with a more condensed way of discussing via issues, so we don't swamp the issue tracker, but for now its good enough I guess.
6:42
or label them as 'discussion' so whoever is not interested in them can blend them out
rickskyy
6:54 PM
we can close them instantly after we come up with the solution (edited)
6:56
I think I will pull after I finish tests -> so everything would looks finished and working
6:57
I hope I will be done with it by tomorrow morning, in worst afternoon (edited)
dumdribille
7:04 PM
I'm off for today, have a nice evening! :slightly_smiling_face:
rickskyy
7:04 PM
you too)

12.07.2017

rickskyy
1:05 PM
hi everyone, please check the hub implementation:
https://github.com/rickskyy/python-odml/commit/64bb4aee5b77eaeb806ccd7ac79b06e54ab43e6c
Since hub is a just a node in the graph, so for now I just pass the id to the constructor of the converter, and add the processing doc to the hub node with the id specified. Then, several docs can be merged by uniting them via similar hubs.
GitHub
[rdf-converter] add links, includes and hub · rickskyy/python-odml@64bb4ae
python-odml - odML libraries and editor
dumdribille
1:17 PM
I'll look it over in the evening! :slightly_smiling_face:
dumdribille
8:21 PM
ok, looked over the code :slightly_smiling_face:
8:22
I got a couple of comments, based on my past experience with rdf
8:23
I think we should not use blank nodes, but rather use named nodes (URIRef) wherever we can
8:25
I also put together a small example illustrating the custom namespace and how to add instances of custom types.
dumdribille
8:25 PM

import uuid
from rdflib import Graph, Namespace, RDF, URIRef
g = Graph()

# create custom odml namespace
ns = Namespace("http://g-node.org/odml-rdf#")

# use a specific prefix for our custom odml namespace
g.bind('odml', ns)

# create named hub node - since the custom id is supposed to be a uuid,
# it should be unique wherever, making it unlikely that two different instances
# have the same id - needs to be replaced
# maybe there is a nicer way to get a proper uuid tough, I'm not a python guy ;)
hubNode = URIRef(uuid.uuid4().urn[9:])

# create named document node
docNode = URIRef(uuid.uuid4().urn[9:])

# add hubNode to graph, add it as RDF type "odml:Hub"
g.add( (hubNode, RDF.type, ns.Hub) )

# add docNode to graph, add it as RDF type "odml:Document"
g.add( (docNode, RDF.type, ns.Document) )

# connect docNode as child of hubNode via predicate "odml:hasDocument"
g.add( (hubNode, ns.hasDocument, docNode) )

dumdribille
8:29 PM
whether the actual instances like hubNode or docNode etc should live under the odml namespace as well since they are instances of nodes under the odml namespace I myself am unsure still.
8:30
but as mentioned above it should never be a graph merging problem, when using a uuid as URIRef.
rickskyy
8:31 PM
yeah good comments I will correct this
8:34
actually as far as I know just uuid.uuid4() generates unique id, so there is no real need to check uniqueness
dumdribille
8:35 PM
perfect :slightly_smiling_face:
8:35
if you have more questions let me know!
8:35
but for today I finally have to go home :wink:
8:37
have a nice evening!

rickskyy
8:39 PM
have one comment
8:39
I think URIRef should be valid urls - pointing to some resource
8:40
docNode = URIRef(uuid.uuid4()) not really different to blank nodes
rickskyy
8:53 PM
"whether the actual instances like hubNode or docNode etc should live under the odml namespace as well since they are instances of nodes under the odml namespace I myself am unsure still."
I think it is not the problem at all. Since uuids are very unique, every odml user will have unique ids for docs and hubs.
8:56
No merging problems at all
8:58
I am not sure about uuids that BNode() constructor generate, I would check this, but I guess they have same uniqueness as uuid.uuid4()
8:59
I will read more about resources (URIRefs) but for now personally, I am for blank nodes in the case.
8:59
Have a nice evening)


13.07.2017

dumdribille
9:51 AM
and we're back :wink:
9:51
The problem with blank nodes is, that any ids they have been given when adding them to the graph are not exported when the graph is saved to a file - they are only there for use within the graph.
9:51
You can see in your example file, that the exported statements are all nested blank nodes enclosed by "[...]"
without exporting the ids they have been given in the graph. When these files are loaded to a graph again,
all the blank nodes would receive unique, but different ids than they had been given before.
9:51
This would render the id not persistently identifiable for our use case. (edited)
9:51
That in turn would cause a problem if there are e.g. Sections in two different documents, that are supposed to be the
same entities. When using blank nodes, this could never be identified in a graph merge, they would live as
independent nodes. Currently this is unlikely since we will create new uuids for all existing documents, but for
future documents importing sections that already have a uuid from another odml document, that is actually
quite likely.
9:51
For this reason I think we have to avoid using blank nodes at all.
9:51
But using just the uuid as URIRef as in my example posted above is actually also wrong. :wink: When exporting the graph
to a file, it will add the filename and location as initial part of the URI e.g.
file:///home/msonntag/Chaos/work/python-odml-dev-yar/465f40c7-d5cf-44de-9f27-7aa186c86d04 which again would not make nodes
uniquely identifiable for a merge.
9:51
So I think the proper way to resolve this is using URIRef(odmlns+uuid) as node identifier. Since a
URI can be a URN (unique name without pointing to an actual resource as a URL does) it would also be formally correct.

rickskyy 11:47 AM
Ok I got it, you are right, I thought this blank node ids is being exported. Since I was using xml and I could actually see ids I used to think that way
rickskyy
1:14 PM
Check this
https://github.com/rickskyy/python-odml/commit/264f1076a7a1dd9b6f1e31b194b68383005085a0
GitHub
[rdf-converter] replace BNode usage with proper urns · rickskyy/python-odml@264f107
python-odml - odML libraries and editor
rickskyy
3:35 PM

    from rdflib import Graph, URIRef, Literal, Namespace
    n = Namespace("http://example.org/")
    id1 = 'starts-with-letters'
    id2 = '14930-starts-with-digits'
    g = Graph()
    g.bind("custom_namespace", n)
    g.add((URIRef(n + id1), n.some_predicate, Literal('object1')))
    g.add((URIRef(n + id2), n.some_predicate, Literal('object2')))
    print(g.serialize(format='pretty-xml').decode("utf-8"))
    print(g.serialize(format='turtle').decode("utf-8"))
    # ------XML-------
    #
    # <?xml version="1.0" encoding="UTF-8"?>
    # <rdf:RDF
    #    xmlns:custom_namespace="http://example.org/"
    #    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    # >
    #   <rdf:Description rdf:about="http://example.org/starts-with-letters">
    #     <custom_namespace:some_predicate>object1</custom_namespace:some_predicate>
    #   </rdf:Description>
    #   <rdf:Description rdf:about="http://example.org/14930-start-with-digits">
    #     <custom_namespace:some_predicate>object2</custom_namespace:some_predicate>
    #   </rdf:Description>
    # </rdf:RDF>
    #
    # ------Turtle-------
    #
    # @prefix custom_namespace: <http://example.org/> .
    # @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
    # @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
    # @prefix xml: <http://www.w3.org/XML/1998/namespace> .
    # @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
    #
    # <http://example.org/14930-start-with-digits> custom_namespace:some_predicate "object2" .
    #
    # custom_namespace:starts-with-letters custom_namespace:some_predicate "object1" .

I found it strange how turtle implementation actually represents URIRefs. It could be confusing to see different representation of ids (as url and as plain string of letters and digits)
rickskyy
5:07 PM
I am working on the rdf-schema right now. I found a nice open-source platform for creating schemas and ontologies from Stanford.http://protege.stanford.edu/products.php#web-protegeQuick demo: https://www.youtube.com/watch?v=QvURiHVXnQQI have created account and started a project. It's possible to work on the same project together if you are registered, so I can share it via the login.
protege.stanford.edu


14.07.2017

rickskyy
1:11 AM
[file]
Here is how the first prototype of the odml-schema looks like. Have some topics to discuss though. Can create issues in the morning.
1) Adding Terminology as class to the schema.
2) Ranges of owl properties.
   Literal or xsd:string ( e.g. for id and reference ), maybe usage of xsd:anyUrl
rickskyy
1:12 AM
[file]
The turtle version.

dumdribille
2:45 PM
and we're back again! :slightly_smiling_face:
2:45
I try to address the questions in the order they appeared here :wink: we really should use issues or a specific question/answer forum so no questions are doomed to oblivion...
2:45
regarding the weird turtle output: I think that only happens, if a class instance only has exactly one predicate.
I think I was able to reproduce it in an example: Hub has additional predicates, looks normal, Document has only one predicate looks weird: (edited)
dumdribille
2:46 PM
    import uuid
    from rdflib import Graph, Namespace, RDF, URIRef
    g = Graph()
    ns = Namespace("http://g-node.org/odml-rdf#")
    g.bind('odml', ns)
    hubNode = URIRef(ns + uuid.uuid4().urn[9:])
    docNode = URIRef(ns + uuid.uuid4().urn[9:])
    g.add( (hubNode, RDF.type, ns.Hub) )
    g.add( (docNode, RDF.type, ns.Document) )
    g.add( (hubNode, ns.hasDocument, docNode) )
    print(g.serialize(format='turtle'))
dumdribille
2:47 PM
    @prefix odml: <http://g-node.org/odml-rdf#> .
    @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
    @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
    @prefix xml: <http://www.w3.org/XML/1998/namespace> .
    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
    odml:ffd9a039-2f77-42ca-a557-3c44e050d995 a odml:Hub ;
        odml:hasDocument <http://g-node.org/odml-rdf#4620f9c6-204a-4bbb-bf5d-485d9451e78f> .

    <http://g-node.org/odml-rdf#4620f9c6-204a-4bbb-bf5d-485d9451e78f> a odml:Document .
dumdribille
2:47 PM
next point up: Protege, cool! I think its really cool you look for tools on your own! :slightly_smiling_face:
2:47
I've never had the chance to work with protege, but a former student here in the office worked with it as
well and was quite happy with it.
2:47
I looked over the schema and it looks quite good so far! :slightly_smiling_face:
2:48
comments to that:
2:48
Perfect, that you already added Terminology as a class! :slightly_smiling_face: I think in addition it will need id and hasSection properties.
2:48
I think the Hub class needs to be in the schema as well.
2:49
link and include will not be exported to RDF, so we don't need them as properties in the schema.
When they are encountered while parsing through the document, they should rather be resolved by copying
data that is not available in the local section from the linked/included section. But maybe we can
have a short hangout with @jgrewe next week to discuss how to properly resolve link and include.
2:49
More comments on the schema I'd rather do in a pull request to reduce description confusion. :wink:
2:49
a couple of general comments:
2:50
Can you find out from the RDF/OWL documentation, if there are naming conventions for Data properties,
Object properties and Classes, post what you find in an issue on github and sanitize what we have so far?
Currently we are using different naming schemes (e.g. odml:terminology and odml:hasDocument) for
comparable edges. It would be good to have naming rules early on and then all stick to it. :wink:
2:50
Can you change the Namespace for our custom terminology everywhere to https://g-node.org/projects/odml-rdf?
2:51
Can you create a pull request with all your code changes and the latest version of the proposed schema?
I think it will be easier to comment, since probably @jgrewe will comment odml specific, @achilleas might give
Python style related comments and I will mainly comment on RDF related topics and I guess it will be easier
to do that with the actual code in a pull request. :wink:
rickskyy
4:39 PM
    <http://g-node.org/odml-rdf#173dac73-2ffc-46d5-9635-52b3d08c1e9a> a odml:Hub ;
        odml:hasDocument odml:e818923e-7765-428e-88cd-4b5eb5b5b06d .
    odml:e818923e-7765-428e-88cd-4b5eb5b5b06d a odml:Document .
    ###############################
    odml:e7888eee-5041-4cea-aea1-b95a32a71c85 a odml:Hub ;
        odml:hasDocument <http://g-node.org/odml-rdf#4e5fdd78-5d4f-4f88-ac82-bd22ca4eb1ce> .

    <http://g-node.org/odml-rdf#4e5fdd78-5d4f-4f88-ac82-bd22ca4eb1ce> a odml:Document .
    #################################
    odml:e4871192-282c-4f2b-882c-67e5f690d550 a odml:Hub ;
        odml:hasDocument odml:ac5a6f45-2f9e-4439-a84d-b2f1c23f2c37 .

    odml:ac5a6f45-2f9e-4439-a84d-b2f1c23f2c37 a odml:Document .
    ###################################
    <http://g-node.org/odml-rdf#2fdc8146-871c-4f5b-9f8d-44d30c96bf5e> a odml:Hub ;
        odml:hasDocument <http://g-node.org/odml-rdf#0950aa00-d51b-435f-a82a-e18164f7915d> .

    <http://g-node.org/odml-rdf#0950aa00-d51b-435f-a82a-e18164f7915d> a odml:Document .
@dumdribille look carefully to your turtle example, the weird representation depends on the id first symbol. Here is the different outputs for your example
rickskyy
4:41 PM
I will add our discussion about shema to the google doc. Should I create an issue for the turtle representation?
4:44
it do not think it depends on the number of predicates in the class
dumdribille
4:53 PM
ah yes, it really seems that it always happens when the uuid starts with a number
4:54
can you check whether this is an issue, if the file is loaded into a graph again?
4:56
yeah, I think an issue would be good as well in this case. :slightly_smiling_face:
rickskyy
5:00 PM
yeah I checked that multiple times
5:01
the solution that appear instantly in mind is add some digit in the start of the id (edited)
5:01
0 + uuid
5:02
for example
5:03
I guess it won't effect anything (the id length would be 33 symbols instead of 32)
dumdribille
5:05 PM
is it just weird when viewing the file or does it actually create issues when loading the file into a graph again.
5:06
if it's just weirdly displayed, but does not effect the graph, I would not care too much
5:06
or switch to a different format where the problem does not occur even if it isn't as nice to view. :wink:
rickskyy
5:11 PM
it is just with the turtle
5:11
xml works nice
5:12
So we can leave it as it is
dumdribille
5:13 PM
does it effect the graph, when you load such a turtle file again?
rickskyy
5:13 PM
of course not
5:13
wait
5:14
I check
rickskyy
5:30 PM
it is do not influence
5:30
the graph
rickskyy
5:32 PM
    import uuid
    from rdflib import Graph, Namespace, RDF, URIRef
    g = Graph()
    ns = Namespace("http://g-node.org/odml-rdf#")
    g.bind('odml', ns)
    hubNode = URIRef(ns + uuid.uuid4().urn[9:])
    docNode = URIRef(ns + uuid.uuid4().urn[9:])
    g.add((hubNode, RDF.type, ns.Hub))
    g.add((docNode, RDF.type, ns.Document))
    g.add((hubNode, ns.hasDocument, docNode))
    print(g.serialize(format='turtle').decode("utf-8"))

    data = g.serialize(format='turtle').decode("utf-8")
    f = open("/home/rick/g-node/python-odml/rdf_dev/example_odmls/test4.xml", "w")
    f.write(data)
    f.close()

    g = Graph()
    g.parse(source="/home/rick/g-node/python-odml/rdf_dev/example_odmls/test4.xml", format="turtle")
    f = open("/home/rick/g-node/python-odml/rdf_dev/example_odmls/test5.xml", "w")
    data = g.serialize(format='turtle').decode("utf-8")
    print(data)
    print(list(g.subject_objects(predicate=ns.hasDocument)))
    f.write(data)
    f.close()
rickskyy
5:32 PM
what I actually did
rickskyy
5:41 PM
    <http://g-node.org/odml-rdf#0e06bd34-2670-4a19-ba59-6a3118a6c8ed> a odml:Hub ;
        odml:hasDocument odml:c7c57f18-7642-4344-bc49-eb1b9903cb7d .
    odml:c7c57f18-7642-4344-bc49-eb1b9903cb7d a odml:Document .
    ## Output: subject and object in the triple with hasDocument predicate
    [(rdflib.term.URIRef('http://g-node.org/odml-rdf#0e06bd34-2670-4a19-ba59-6a3118a6c8ed'), rdflib.term.URIRef('http://g-node.org/odml-rdf#c7c57f18-7642-4344-bc49-eb1b9903cb7d'))]
Yeah I am definitely sure this bug does not influence the graph
dumdribille
5:47 PM
ok cool, then I would not worry too much about it. (edited)
5:48
but please create an issue with what we learned so far nonetheless so we can come back to it e.g. for tutorial or documentation purposes.
rickskyy
5:53 PM
ok, I will do it right now
rickskyy
6:17 PM
added
rickskyy
6:51 PM
The only drawback the protege has that for renaming parts of IRIs (for example terminology to hasTerminology) of an entity (class, property) I need to recreate the object =( (edited)
rickskyy
7:02 PM
created pr
rickskyy
7:43 PM
i included ontology to the pr. But what to remind you that we can edit the schema in protege together if you register an account so I could share the project.
7:44
Also there is a version control mechanism and tools for discussing and proposing changes.

17.07.2017

rickskyy
1:31 PM
Hi everyone, want to check if there would be the hangouts meeting today
dumdribille
2:34 PM
Hi!
2:35
sorry for the late response, we just had a kinda general gnode meeting today.
2:35
but we briefly discussed with @jgrewe, that it might be good to have a hangout tomorrow afternoon to discuss the link and include topic if that is fine with you.
2:36
thx for the pull request! regarding this we have a favor to ask: could you split this one
up into a couple of smaller pull requests, so that we can more easily divide the review
process amongst ourselves? we usually do smaller, topic specific pull requests on a regular basis.
That makes them easy to review and easy to discuss and fast to introduce changes.
2:36
Could you please split up the current pull request into the following four?
- updates to odml core
- ontology, rdf example files
- rdf_converter, example/rdf_generator
- tests
2:36
Regarding Protege: I registered, you can invite me as "mpsonntag"", but I really would like
to have the discussions via pull requests or issues on github, since there any discussion
will be transparent and available to anyone that is interested or investing in the python-odml
project.
2:36
That said, thx a lot for your work so far! It looks really good and we are happy to see you
work on your own, figuring out stuff so well! :slightly_smiling_face:
2:36
Keep that in mind, when we put tons of comments and change requests on the pull request. :wink:
rickskyy
2:50 PM
Meeting tomorrow is good for me. Let me know when you decide about the time. I am available during the whole day tomorrow.
2:51
Thanks for appreciation of my work )
2:51
I will split the pr into smaller ones soon.
2:54
Regarding Protege, I do not say we should discuss all the stuff there, I meant it is just a more convenient way to see the whole project and rather quick to make and review changes that just managing file on github.
2:56
Besides, I did not see at first I could share the project via the link, here it is:
https://webprotege.stanford.edu/#projects/b6d54bcc-da44-44bf-aab8-1b98455cea9a/sharing
dumdribille
3:11 PM
cool, worked like a charm :slightly_smiling_face:
rickskyy
3:14 PM
this version may not be consistent with what I added to pr, since it is impossible to changes IRIs without deleting the object in protege.
3:16
hasTerminology has "https://g-node.org/projects/odml-rdf#terminology" in protege version and in the pr it is  "https://g-node.org/projects/odml-rdf#hasTerminology"
3:17
I changed that manually
3:17
so that is the big drawback of the system, maybe there is a way to do this but I have not found it yet (edited)
3:20
Finally, I think it's better to discuss everything on github or here, and everyone could upload the last version of the project to the Protege for yourself if he wants
jgrewe
4:50 PM
hey folks, can we delay a hangout meeting to Wednesday? Got a new appointment for tmorrow...
4:50
sorry for the trouble
dumdribille
4:53 PM
no objections from my end :slightly_smiling_face:
rickskyy
6:26 PM
me too ))


18.07.2017

rickskyy
9:15 AM
I added 4 new PRs as Michael asked. I did not delete the first big PR, so you can see the passing builds from travis and test coverage. Since core changes was separated to the separate pr, the rdf converter and tests failed the build checks.
rickskyy
10:54 AM
If you have questions let me know. Actually I committed my file changes again with more cleaner structure and messages, so the first big PR and those branch (rdf-converter) would be deleted finally.
dumdribille
11:16 AM
I have one PR general comment: the PR "[rdf] Add odml-rdf converter" is against G-Node:master. :wink:
11:16
all the other ones are fine though (edited)
rickskyy
11:24 AM
oh sorry
11:28
fixed that
dumdribille
12:46 PM
np :wink:
rickskyy
5:18 PM
@dumdribille I deleted the previous version of ontology in Protege due to IRIs constrains, I shared the new one to you. Here is a link for everyone: https://webprotege.stanford.edu/#projects/640a5c50-33f4-4900-a8c5-6386deba8325/sharing (edited)
dumdribille
5:43 PM
cool, thx!


19.07.2017

dumdribille 10:58 AM
@jgrewe @rickskyy do you want to do a hangout today or just chat about stuff?
jgrewe
10:59 AM
I fell much behind, so a quick hangout will probably be more efficient
dumdribille
11:00 AM
I have time between 13:00 and 17:00
jgrewe
11:01 AM
I'd prefer the later afternoon, say 16:00?
rickskyy
11:18 AM
17.00 (Kyiv) works well for me
dumdribille
11:20 AM
perfect!
jgrewe
11:21 AM
so then it's settled
11:21
see you later
dumdribille
1:00 PM
@rickskyy I played around with the webprotege
1:01
it really can drive one insane with respect to the IRIs...
1:02
I think I managed to get out the kinks with respect to the IRIs and to resolve the rdf:Bag issue by manually editing the downloaded file and reimporting
1:02
not sure if this is the proper way to go, but I don't want to spend too much time on the tool itself. :wink:
dumdribille
1:03 PM

dumdribille
1:04 PM
you can easily import this into webprotege, let me know what you think!
rickskyy
1:44 PM
oh it is nice
1:44
it is much better than custom Bag class that I created
1:45
It is really a good way to include publicly defined classes
1:47
:blush:
dumdribille
2:31 PM
I hope its actually correct, but I think its good enough for now. :wink:
2:32
maybe we have to revisit the topic once we are at the first query and see this construct does not work as its supposed to...
rickskyy
3:09 PM

dumdribille
4:02 PM
hi guys
jgrewe
4:02 PM
hey
dumdribille
4:02 PM
I opened an lrz hangout at meet.lrz.de/odml2rdf
jgrewe
4:03 PM
let’s see if that works :slightly_smiling_face:
jgrewe
4:16 PM
https://github.com/G-Node/odml-terminologies/blob/master/v1.0/cell/cell.xml
GitHub
G-Node/odml-terminologies
odml-terminologies defining terms to annotate electrophysiological data
rickskyy
4:28 PM
https://docs.google.com/document/d/1EZu6g8TG2ZzoJaXNaTeMDFY5yQTJh1RRm6vf675bMsM/edit#
jgrewe
4:36 PM
https://web.gin.g-node.org/G-Node/odmlFiles


20.07.2017

dumdribille
2:55 PM
@jgrewe are you ok with it if I merge the 4 PRs now?
2:56
@rickskyy the 5th one can then be closed, right? All the commits from #110 are in other PRs?
slackbot APP
2:56 PM
Only visible to you
You mentioned @rickskyy, but they’re not in this channel. Would you like to invite them to join or have Slackbot send them a link to your message? Or, do nothing.
jgrewe
2:56 PM
yeah, sorry, go ahead
dumdribille
2:57 PM
merge heaven :smile:
achilleas
2:57 PM
\o/
jgrewe
2:57 PM
lots of green dotses
dumdribille
2:58 PM
we can split them if you want :wink:
github APP
2:58 PM
[G-Node/python-odml] Pull request closed: #115 [rdf] Adding odml ontology by mpsonntag
2:58
[python-odml:dev-odml-rdf] 5 new commits by yshalivskyy and 1 other:
1fa1754 [rdf] add an example rdf file and its generator - yshalivskyy
f8a7556 [rdf] add the odml ontology - yshalivskyy
3408c7c [rdf] ontology improvements - yshalivskyy
b5986b3 [rdf] update ontology, remove .owl ontology file - yshalivskyy
3629800 Merge pull request #115 from rickskyy/ontology - Michael Sonntag
achilleas
2:58 PM
well, you don't get the greens until it's merged into master
github APP
3:01 PM
[G-Node/python-odml] Pull request closed: #113 [rdf] Changes to core by mpsonntag
3:01
[python-odml:dev-odml-rdf] 5 new commits by yshalivskyy and 1 other:
720f6b1 [rdf] changes to the odml core module - yshalivskyy
1c80fd9 [rdf] add rdflib to setup.py and travis.yml - yshalivskyy
fba563c [rdf] remove id.setter - yshalivskyy
484186f [rdf] removing id attr from constructors - yshalivskyy
89e7c80 Merge pull request #113 from rickskyy/core-changes - Michael Sonntag
jgrewe
3:01 PM
so unfair
github APP
3:02 PM
[G-Node/python-odml] Pull request closed: #114 [rdf] Add odml-rdf converter by mpsonntag
3:02
[python-odml:dev-odml-rdf] 6 new commits by yshalivskyy and 2 others:
f3e1564 [rdf] update THGTTG.odml with ids - yshalivskyy
61bfa02 [rdf] add RDFWriter class for the odml-rdf conversion - yshalivskyy
6a355ff [rdf] add example files used for manual testing - Yaroslav Shalivskyy
d44e95e [rdf] add generator for ex_1.odml - yshalivskyy
81cc66c [rdf] bug fixes and structure improvements - yshalivskyy Show more…
jgrewe
3:02 PM
work now, and rewards later...
github APP
3:02 PM
[G-Node/python-odml] Pull request closed: #116 [rdf] Add tests for the RDFWriter class by mpsonntag
3:02
[python-odml:dev-odml-rdf] 2 new commits by yshalivskyy and 1 other:
4aa029b [rdf] add tests for the RDFWriter class - yshalivskyy
0d10b10 Merge pull request #116 from rickskyy/tests - Michael Sonntag
achilleas
3:03 PM
yeah these delayed rewards are really messing up our positive reinforcement mechanisms
github APP
3:40 PM
[G-Node/python-odml] Pull request closed: #110 [rdf] Adding odml-rdf converter and odml ontology prototypes by rickskyy
rickskyy
6:36 PM
rickskyy
6:36 PM
Hello everyone, I need some help with ids.
When the id attr was deleted from constructor XMLReader stopped working and raise exceptions like:
Exception: __init__() got an unexpected keyword argument 'id'.
After debugging I realized that it happens when the new object (section, property, doc) is created with attributes of
None values. The dict with attributes and their values is being passed to object constructor. Since we do not have id
attribute in the constructor any more, this exception is raised.
There is a duct tape solution for this like not passing id attr to arguments while parsing the odml document and save
it locally to a variable, then assign it to the obj._id when setting all properties. However, it would look ugly. After
some time I have not find any ways to manage this. Too many parts of the module should be rewritten than.
For now I can just add ids to the constructor again although they are not using, or use the duct tape I was written
earlier. What do you think? Maybe after implementing rdf-odml converter I could rewrite XMLReader but I think it's not
what important at the moment.
P.S. You can see the log on travis: https://travis-ci.org/G-Node/python-odml/jobs/255332260 (edited)

21.07.2017
rickskyy
1:00 PM
@dumdribille @jgrewe Have a question about parsing files. As I saw files from gin repo are all in the old format
(version 1 not 1.1) so value tags contain type unit e.g. ('        <value>25<unit>kHz</unit><type>int</type></value>')
I am wondering if we had any converter to make them compatible with the new model. I guess we do not, so I am writing
a short module to do this, am I right?
jgrewe
1:03 PM
That would be most welcome :grinning:
achilleas
1:03 PM
I'm having a look at the id in constructor from yesterday
1:08
Right, I see
1:08
Yeah, so the arguments passed to the constructor are being determined by the dictionaries in the format file
1:09
and the dict specifies that our objects have ids, so it passes to the constructor and ... stuff happens
1:09
There's a few dirty solutions here
1:10
One, like you mentioned, is to just accept id in the constructor and ignore it
1:10
Another would be to have **kwargs in the constructor, which is even uglier
1:10
Not sure if making a special case for id when reading in is a great solution either...
1:11
What if we put id=None in the constructor and instead of ignoring it, we check whether it's a valid UUID4 and use that
to set the initial ID?
1:12
Parsing/loading is a pretty common operation, so having a constructor that allows it to be specified (for loading) is
kinda reasonable.
1:12
It's better than having a method/constructor signature that includes arguments that are ignored.
1:15
then we would also be able to remove the special case we have in the xmlparser xmlparser.py:299 were we set obj._id = v
1:17
This kinda sorta contradicts our decision to not have an id property setter, but I think the constructor can have
different rules. It signals that on creation of an object, one can specify an id, but it is (or should be) unchangeable
beyond that.
rickskyy
2:13 PM
@achilleas good suggestion about ids, what place would you recommend to integrate like-this function to? Or just paste
try-except in every constructor for doc, section ...
def id_setter(id):
  try:
       val = str(uuid.UUID(id))
  except ValueError:
       val = str(uuid.uuid4())
  return val (edited)
achilleas
2:15 PM
You could just do it in the constructor, I guess
2:16
I dunno what the behaviour should be for invalid IDs though
2:16
like if  I call Property(name="foo", id="invalid ID"), should it throw an exception?
2:17
Perhaps it should
rickskyy
2:17 PM
the uuid lib raise Value error exception in this situations
achilleas
2:17 PM
yeah
2:17
we could propagate it upwards
rickskyy
2:17 PM
the question what we do if this happens
2:17
like print smth to the user maybe
achilleas
2:18 PM
catch the exception and raise ValueError("Invalid id string: Must be UUID4") ?
2:18
¯\_(ツ)_/¯
2:18
I'd like to hear Jan's take on this
rickskyy
2:19 PM
still we need to assign a valid id
achilleas
2:19 PM
He's more in touch with usability in odml :slightly_smiling_face:
rickskyy
2:21 PM
I also think we do not need to raise an exception again (edited)
2:21
because it was actually raised by uuid and we can except it (edited)
2:22
so we can just print an error message and assign valid id. What do you think? (edited)
2:25
like this:
def id_setter(id):
   try:
       val = str(uuid.UUID(id))
   except ValueError as e:
       print(e)
       val = str(uuid.uuid4())
   return val
2:25
for invalid id it prints:
badly formed hexadecimal UUID string
9f187f00-88f8-45d6-9986-3ca08643a9cd

24.07.2017

rickskyy
10:37 AM
Hi guys, added a first version of odml_version_converter:
https://github.com/rickskyy/python-odml/commit/7f25b0f5208e0482f672f2b096274a9c9106726a
I parsed all the files from gin repo, filtered non odmls, fixed problems related to xml (not matching tags, corrupted
odml docs, same name occurrence in Sections and more). Although the implementation is not pretty good and universal, if
we want to add some kind of similar converter to odml master it's need to be improved in terms of class architecture
and public api functions. There are comments in every function and description for the VersionConverter class.
Looking for feedback.
GitHub
[version-converter] add VersionConverter class and parsed files · rickskyy/python-odml@7f25b0f
python-odml - odML libraries and editor
jgrewe
10:44 AM
hi, no, never had the git problem. What does it tell you? Is there something in your .gitignore?
rickskyy
10:45 AM
sorry
10:45
I forgot about gitignore
10:45
fixed that :blush: (edited)
jgrewe
10:46 AM
hehe, happens to the best :slightly_smiling_face:
rickskyy
10:46 AM
just deleted restrictions for .odml
dumdribille
11:14 AM
very cool!
11:14
could you please create a pull request for just the converter? its easier to find and review then. :wink:
rickskyy
11:14 AM
ok
11:18
what about ids? what solution do we stick for?
11:19
for now this pr would not be built on travis
dumdribille
11:21 AM
I'd say make one pull request for the converter and one for the id changes. it does not matter if the pull request does
not build for now. we can discuss there right with the code and decide which way to go.
rickskyy
11:24 AM
ok
dumdribille
11:33 AM
could you please exclude all gin files from the PR? this many example files should not go to the repository. :slightly_smiling_face:
dumdribille
11:48 AM
yaaaay, the PR builds successfully! :smile:
rickskyy
12:26 PM
ok
dumdribille
12:53 PM
cool, thx! sorry for the back and forth!
rickskyy
1:14 PM
Oh that is fine
1:15
Unfortunately, I can respond to comments and suggestions only in the evening today, just to let you know
dumdribille
2:56 PM
no problemo :slightly_smiling_face:
2:57
@rickskyy I had the chance to talk to Thomas and he said everything is fine with contract. :slightly_smiling_face:
2:57
and regarding the visit in munich
2:58
you said you would visit on 01.09.2017, right?
2:59
I think at that particular day its just me that would be in Munich, everyone else is on vacation.
3:00
if you still want to visit, which would be awesome, we would pay for the trip from berlin to Munich and the hotel fr-sa.
3:00
and I am sure also for the food and partly drinks on friday :wink:
3:01
It would really be nice to meet you in person, but its totally up to you, if that does not fit with your travel plans. :slightly_smiling_face:

rickskyy
8:28 PM
That is ok, I do not think I would have a chance in the near future to visit Munich, so I am really looking forward to
come. Thank you for proposition, but I do not think you need to pay for me)) Also as I mentioned before, I will come
with my friend, so I would be very thankful if you find the room with two beds for us.


25.07.2017

rickskyy
12:12 PM
Hi everyone, @dumdribille @jgrewe will we have a meeting today?
rickskyy
12:39 PM
Have some questions related to the last PR. Want to discuss suggestions and general concepts for version converter and automate converter for directories.
dumdribille
12:47 PM
we have a meeting from 13:00 probably until 14:00, but I afterwards we should have time for a hangout! :slightly_smiling_face:
rickskyy
1:11 PM
good
jgrewe
2:49 PM
soo, basically I would be available for a meeting
dumdribille
2:49 PM
meeting tuesday :wink:
jgrewe
2:50 PM
indeed
dumdribille
2:53 PM
@rickskyy you wanna chat or rather do a hangout thingy?
rickskyy
2:53 PM
hangout thing will be quicker I guess but
2:53
I am also ready to chat
dumdribille
2:53 PM
meet.lrz.de/rdfthingy
2:54
lets try it again and then fall back to hangout
jgrewe
3:06 PM
argparse
3:07
if __name__ == '__main__':
   # command line arguments:
   parser = argparse.ArgumentParser(
       description='Display waveform, spectrogram, and power spectrum of time series data.',
       epilog='by bendalab (2015/2016)')
   parser.add_argument('--version', action='version', version='1.0')
   parser.add_argument('-v', action='count', dest='verbose')
   parser.add_argument('file', nargs='?', default='', type=str, help='name of the file wih the time series data')
   parser.add_argument('channel', nargs='?', default=0, type=int, help='channel to be displayed')
   parser.add_argument('output_folder', nargs='?', default=".", type=str, help="location to store results, figures")
   args = parser.parse_args()
main(args.file, args.channel, args.output_folder, args.verbose)
rickskyy
3:41 PM
8.xml
3:41
line 14 and 54
jgrewe
4:07 PM
https://en.wikipedia.org/wiki/Merkle_tree


26.07.2017

dumdribille
3:15 PM
I added the proposed xsd types for all RDF leaves to our google doc, xsd:string nearly everywhere :wink:
rickskyy
3:40 PM
Q&A Section is good)
rickskyy
3:59 PM
Made it a little better
dumdribille
4:03 PM
cool! :slightly_smiling_face:
4:04
I actually still prefer issues, but maybe as an intermediate option for documented discussion/place to put opinions. :wink:
rickskyy
4:05 PM
Totally agree (edited)
dumdribille
5:05 PM
I also just updated the example graph in the google doc with the proposed cardinalities of the individual predicates. Maybe @jgrewe, you can check whether these make sense from an odml perspective. (edited)
jgrewe
5:06 PM
having a talk now, will check later
dumdribille
5:07 PM
no hurry, just wanted to keep everyone informed :slightly_smiling_face:
5:07
* that stuff has happened


27.07.2017

dumdribille
11:05 AM
I just merged the 'Changes to ids' PR. @rickskyy, could you rebase the second PR with these changes, so the tests will unfail? :slightly_smiling_face:
rickskyy
12:23 PM
ok
rickskyy
12:29 PM
I think I will make another PR soon and close and old one
12:30
there would be quite a change, is it ok? (edited)
rickskyy
12:37 PM
Finally, I just rebased :slightly_smiling_face: add commits soon with new code
12:38
used to the opinion that rebasing public repos is bad practice but in this case it is ok


28.07.2017
dumdribille 12:16 PM
@rickskyy cool, thx for the changes on the PR! unfortunately I won't be able to review them though today...
12:17
@jgrewe the PR is failing due to decreases in coverage. should we ignore it or lower the threshold for fails due to coverage decrease?
achilleas
12:17 PM
What's the diff (how much is the decrease)? (edited)
dumdribille
12:18 PM
-6.6%
achilleas
12:18 PM
I think increasing the threshold above that would be too much.
12:19
Then again, we might say screw coverage and disable failing altogether. Let's wait for @jgrewe weigh in
jgrewe
1:02 PM
i would ignore it for this pr


01.08.2017
rickskyy
8:42 AM
Hello everyone, I will be in the countryside during next couple of days and will be working from there. Probably, I would be mostly offline, but will try to chat. Not sure about the strength of the Internet connection there, so I ask you to postpone today meeting for the next week. I plan to work on odml-jsonld converter.
dumdribille
3:30 PM
that fits perfectly, since we are also quite tied up with the data course we are currently hosting. we probably will have more screentime starting tomorrow when everything is set up and running smoothly. :wink:
3:30
enjoy the countryside!
rickskyy
7:55 PM
Good, thank you)


07.08.2017
dumdribille
5:08 PM
@rickskyy the course is over and we are back!
5:09
Regarding your visit in Munich, we would book a room close to the university for two persons for one night from
01.09-02.09.2017. We would just need your full names for the booking.
5:09
If you want to stay longer, you would need to book that on your own. Unfortunately we as Munich residents do not have
much experience with the hotels here, but in general the ibis hotel chains are ok. With the ibis München City Nord you
are on a subway directly to the city center. another option would be the Best Western Atrium Hotel which is close to
the main train station. a friend of mine stayed in and was really happy with the hotel itself, but its in a bit of a
shabby part of the city.


08.08.2017

dumdribille
12:19 PM
@rickskyy I talked to Thomas and sent him your information, so the hotel should be organized in the next days. lets keep our fingers crossed. :wink: he also said, if you keep your stamped train ticket from Berlin to Munich we can reimburse you for that as well.
rickskyy
12:21 PM
Great, thank you. Regarding the train, we decided to take a bus from Berlin to Munich since it is only 7 hour trip and it is cheaper on 40 euros. (edited)
dumdribille
12:52 PM
That should be fine as well.
12:53
we have a meeting for one of our projects starting at 13:00, I'll holler when we are back!
rickskyy
12:57 PM
Good, saw new issues, will work on them soon. Now working on the new PR which will include extension to FormatConverter for odml-rdf conversion and some fixes for validation issues. Also have some questions related to validation, so looking forward to the meeting.
dumdribille
3:48 PM
we're back!
3:48
@rickskyy do you want to do a hangout thingy?
rickskyy
3:49 PM
can text
3:49
up to you
3:50
want to clarify work plan for the next week
3:52
The PRs with some extensions and solved issues you opened about property attrs will be finished till tomorrow, so we can discuss them then
dumdribille
3:52 PM
cool
3:53
did you already get anywhere regarding one or two example SPARQL queries so we know how the graph actually behaves when being queried?
rickskyy
3:53 PM
not yet
3:54
can do it today
dumdribille
3:54 PM
in general, did you see the github project I created on the G-Node/python-odml?
rickskyy
3:54 PM
no)
dumdribille
3:54 PM
I think that might be nice to put in tasks in point out which need more discussion
3:55
I will put an additional issue in there for the SPARQL task
3:55
@jgrewe I am unsure how to best approach the valueOrigin issue
rickskyy
3:56 PM
this is cool, looks like Trello, did not use Projects on github before )
dumdribille
3:56 PM
yeah I am starting to like it as well :slightly_smiling_face:
rickskyy
3:57 PM
could I edit them? (edited)
jgrewe
3:57 PM
valueOrigin
dumdribille
3:58 PM
sure, go crazy
jgrewe
3:58 PM
what do you want to do?
3:58
I mean at the moment the field does not exist
dumdribille
3:58 PM
@jgrewe should we implement the valueOrigin in the python-odml core just in the rdf branch or in the main branch and import
3:58
cherry pick
jgrewe
3:58 PM
both would be fine with me
3:59
if we do it in master, then digaru has it to adjust the ui
dumdribille
4:00 PM
@rickskyy would you be comfortable with adding this field in a python-odml master branch and create a PR there before importing these changes to the rdf-dev branch?
rickskyy
4:01 PM
Yeah fine, just let me understand what does this field mean :smiley:
dumdribille
4:01 PM
It's with respect to this issue: https://github.com/G-Node/python-odml/issues/130
GitHub
Keeping a source attribute for metadata values · Issue #130 · G-Node/python-odml
Currently (in v1.3) the value objects have a reference and a filename attribute. We are still using the filename attribute to state where the metadata value in the property was generated/extracted ...
4:02
during the refactoring of the Value entity, fields will be completely removed and some of our collaborators want to store the filename of where the value originally came from
4:03
this field would be added to the python-odml Property to provide this feature
4:05
So the first step would be to implement and merge this into python-odml master, then import into the rdf-dev branch, add this field to the ontology and then include it into the RDF export as well
rickskyy
4:06 PM
got it
4:06
so basically it's a url to the source or the filename?
dumdribille
4:06 PM
yes, exactly
rickskyy
4:07 PM
referencing to just a filename maybe have less sense than url
dumdribille
4:07 PM
if I got it right it could also just be a text containing the filename with any other path whatsoever just for provenance sake
rickskyy
4:08 PM
:sweat_smile:
dumdribille
4:08 PM
yeah...
4:09
it might make sense in more complicated queries e.g. to find all properties that where created from a specific filename
rickskyy
4:09 PM
so in ontology it is will be string and that's all
dumdribille
4:09 PM
but that is just me gessing now
4:09
*guessing
4:09
yes, just a string should be sufficient
rickskyy
4:09 PM
good
4:10
also  I did not find the way to edit project on github
dumdribille
4:10 PM
hm, maybe I have to add people in the settings somehow, let me check
rickskyy
4:10 PM
maybe there should some rights delegation
dumdribille
4:11 PM
can you at least add issues as cards?
rickskyy
4:11 PM
no
dumdribille
4:11 PM
lame
rickskyy
4:11 PM
send me a sreenshot how you do this
4:11
I guess there might be some buttons or whatever
4:12
because now I have nothing
dumdribille
4:15 PM
working on it
rickskyy
4:16 PM
yeah I saw the intro video and there is edit buttons which I do not have
dumdribille
4:16 PM
but if its ok, I'll assign you the above referenced issue :slightly_smiling_face:
4:17
ok, I added you as collaborator, can you check if your permissions have changed?
4:17
you should have received an invitation to python-odml
4:17
via github
4:17
I think
4:17
maybe
rickskyy
4:18 PM
yeah it works thanks
dumdribille
4:18 PM
awesome
dumdribille
4:24 PM
ok, I am currently coming up with an issue regarding the SPARQL task
4:26
@jgrewe do you have any ideas what would be good queries
4:26
from your point of view?
4:27
what would you query, if your files would be in a databaes
4:27
*database
4:27
maybe that would be then also good real life oriented quereies
4:27
*queries
4:27
sorry, typing broken today
jgrewe
4:27 PM
haha, that reminds me of a task i still have to fulfill
dumdribille
4:28 PM
??
jgrewe
4:28 PM
if my data was in the hub I would ask for certain stimulus conditions.
4:28
in the case of the drosophila data we should ask cgars
dumdribille
4:29 PM
I think starting to play with your data should be good enough for now to see if the basal structure is ok for quereies
jgrewe
4:29 PM
@dumdribille I promised to export some odml for our nix files
dumdribille
4:29 PM
ah yes :slightly_smiling_face:
jgrewe
4:29 PM
ok. let me see
dumdribille
4:30 PM
I created an issue, maybe you could add one or two real live queries as comments
4:31
what the WHERE clause would be and which fields you would expect as results
4:31
also added it already to the project :wink:
jgrewe
4:31 PM
ok, which issue is that?
dumdribille
4:31 PM
#142
4:31
in the ToDo (prerequisit) column
jgrewe
4:31 PM
thks, just saw the message in the other channel
dumdribille
4:34 PM
@rickskyy I will be gone on vacation for the next two weeks starting friday
4:34
should we draft a rough list of issues for these weeks?
rickskyy
4:35 PM
yeah this will be nice
4:35
we can talk tomorrow
4:35
or today
dumdribille
4:35 PM
from my point of view I would do:
1) SPARQL query, check if its nice
4:35
and refactor schema if necessary
4:36
2) write RDF 2 odML converter
4:37
3) start subclassing Section / Properties with odML use case specific terms; I will put an example how I imagine this in an issue
rickskyy
4:37 PM
3rd did not understand
dumdribille
4:37 PM
4) if there is time or you feel like it polish the odML converter
rickskyy
4:38 PM
let's write this down in my google doc
dumdribille
4:38 PM
I think it would be best if I draft an example for the 3rd one
rickskyy
4:38 PM
ok
dumdribille
4:38 PM
you said you also wanted to work on the json converter, right?
4:38
is this the PR that will be coming up?
rickskyy
4:39 PM
rdflib has plugin for jsonld
dumdribille
4:39 PM
aaah, cool
rickskyy
4:39 PM
I just added it
dumdribille
4:39 PM
very cool
4:39
looking forward to seeing this.;)
rickskyy
4:39 PM
the question is if it works well
4:39
hahah
4:40
I guess I will need to add some stuff manually or edit graph
4:41
for now it works, but I am still researching and reading if the result is good
dumdribille
4:42 PM
@jgrewe cool, just saw the comment on the SPARQL issue
4:45
@rickskyy would you be cool with using jupyter notebooks for writing the example SPARQL queries? the nice thing about them is, that you can just work like in an ipython window but afterwards we already have something that can easily be converted into an interactive tutorial.
rickskyy
4:46 PM
I think I will cope with it
dumdribille
4:46 PM
:smile:
rickskyy
4:46 PM
:blush:
dumdribille
4:46 PM
ok
4:47
I think I need a bit of thinking to draft the issues for point 3 and 4
4:47
should I write them up and we can discuss this and the coming PR on Thursday?
4:47
because after that I am off :slightly_smiling_face:
rickskyy
4:48 PM
yeah sounds cool
dumdribille
4:48 PM
do you have any questions or other stuff for now?
4:49
@jgrewe do you have any other stuff on your mind?
jgrewe
4:50 PM
no, I think that's fine for the moment
dumdribille
4:52 PM
awesome! then I declare the meeting adjourned for now (if everyone agrees)
jgrewe
4:53 PM
hehe, do so :slightly_smiling_face:
rickskyy
4:54 PM
agree)
dumdribille
4:55 PM
cool, if any questions pop up, we are here :wink:

rickskyy
5:07 PM
just added the value_origin PR, check please
5:08
@dumdribille Now has a small temptation to close my own PRs heh))
dumdribille
5:10 PM
nice
dumdribille
5:16 PM
ok, the PR has my approval :wink:
jgrewe
5:17 PM
did you see my comment?
dumdribille
5:17 PM
just now yes
jgrewe
5:17 PM
:wink:
dumdribille
5:17 PM
forgot about the format
5:17
naughty
jgrewe
5:18 PM
just a tiny fix, I hope
5:18
@rickskyy  the writing should be tested as well
rickskyy
5:19 PM
i change the format
jgrewe
5:19 PM
cool
dumdribille
5:19 PM
I checked test_property.py and its nearly all pass, amazing...
rickskyy
5:19 PM
test_property does not really checks all attrs
check the commit
5:25
Do such kind of tests are valuable?
dumdribille
5:26 PM
from my point of view they are helpful when refactoring and you overlook sthg
5:26
other than that...
rickskyy
5:26 PM
+0.01% lol
dumdribille
5:27 PM
:smile:
jgrewe
5:27 PM
By now I feel much better when tests are there and I notice when I break something.
rickskyy
5:27 PM
yeah thanks)
5:28
I think I can enhance tests as one of the tasks for the next week
dumdribille
5:28 PM
if you don't mind, that would be awesome
rickskyy
5:30 PM
@jgrewe could you approve and close, so I process further?
jgrewe
5:36 PM
I am struggling with the test, tbh. What I miss is the testing of actual writing and reading from file
rickskyy
5:36 PM
oh
5:37
Yeah I can implement this through StringIO, as I did with converters (edited)
jgrewe
5:38 PM
let it sink for a bit, Read-Write is tested in test_samplefile.py, but I do not completely understand how it works, never really looked to it, to be honest (edited)
5:39
I'm misspelling a lot, maybe I should go home :slightly_smiling_face:
rickskyy
5:40 PM
this part does all the magic:
def test_restore(self):
       try:
           from StringIO import StringIO
       except ImportError:
           from io import StringIO
       modules = [(xmlparser.XMLWriter, xmlparser.XMLReader)]
       # (jsonparser.JSONWriter, jsonparser.JSONReader)]        for Writer, Reader in modules:            doc = Writer(self.doc)
           if sys.version_info < (3, 0):
               doc = StringIO(unicode(doc))
           else:
               doc = StringIO(str(doc))
           doc = Reader().fromFile(doc)
           self.assertEqual(doc, self.doc) (edited)
jgrewe
5:42 PM
now it depends on the features that are in self.doc
rickskyy
5:58 PM
The solution I see here is just extend SampleFileCreator with all properties we have, so the SampleFileOperationTest.test restore() can check this, or change SampleFileOperationTest.test_restore() so we can pass docs created with SampleFileCreator directly as params and create test funcs for every attribute in specific to the entity modules (edited)
6:00
the last suggestion will take more time, but ensures that we have at least one test for every entity attr so later we can add some meaningful tests for them if needed (edited)


09.08.2017

dumdribille
3:28 PM
While reviewing I just realized sthg I overlooked in the previous rdf_converter PR
3:29
currently the hub gets an id which is not what we had in mind from the beginning.
3:30
if we imagine a merge between two graphs, we ideally want them merged via the same hub
3:30
we can't do that, if the hub of two graphs have different ids
rickskyy
3:31 PM
you want to say we need to set hub id by default
dumdribille
3:31 PM
no, the hub has no id
3:31
it does not need one :slightly_smiling_face:
3:32
thats why there is none in the conversion description
3:32
but I completely blanked on that while reviewing the converter PR
3:33
so hub id should be removed again, sry
rickskyy
3:33 PM
that's fine
rickskyy
4:05 PM
@dumdribille I am just trying to understand what would be the subject of the triple which describe Hub. Smth like this:
odml:Hub
   odml:hasDocument <https://g-node.org/projects/odml-rdf#id_doc>,
       <https://g-node.org/projects/odml-rdf#id_doc2> ;
   odml:hasTerminology <https://g-node.org/projects/odml-rdf#id_terminology> .? (edited)
rickskyy
5:38 PM
I think it is fine


10.08.2017
dumdribille
10:32 AM
that is actually a good question...
10:33
I would have said the example you posted above is ok, but could you try creating two RDF graphs with the implementation above and then merging them, checking, if they were properly merged via exactly one Hub node?
rickskyy
11:14 AM
Ok will try now. Sorry about issue with ids I guess I missed it while merging , will fix now
dumdribille
11:14 AM
no problemo, I'm fuzzy on the details here as well. :wink:
11:15
trial and error will show us the way
11:18
We might need a constant id for the Hub in the end which is the same everywhere to make it available for a merge, but it can't be a random UUID every time we export a document.
rickskyy
12:16 PM
The URI like https://g-node.org/projects/odml-rdf#Hub works as an id, in above logic there are not much sense to have constant id everywhere I think (edited)
rickskyy
12:33 PM
ex_1.ttl
I tested merging graphs as it is without id and I think it works well, here is files testes
rickskyy
12:35 PM
ex_2.ttl
rickskyy
12:35 PM
merge.ttl
rickskyy
12:38 PM
The script
dumdribille
12:51 PM
awesome, thats perfect!
rickskyy
12:52 PM
Wait minute before closing PR is it ok
dumdribille
12:52 PM
then we can remove the hub.id everywhere with good conscience :wink:
rickskyy
12:52 PM
Have some fixes
12:53
Yeah that is what I wanted to do finally
rickskyy
1:57 PM
saw your request changed that but ran into some odd error with another stuff, trying to fix
dumdribille
1:57 PM
no hurries!
rickskyy
1:57 PM
While using argparse and calling funcs from terminal got this:
   RDFWriter(odml.load(input_path)).write_file(output_path, res_format)
TypeError: write_file() takes exactly 2 arguments (3 given)
1:57
I am just stuck a little
1:58
how it possible
dumdribille
1:58 PM
thats odd
rickskyy
1:58 PM
but when calling that funcs from a test script not terminal everything is fine
1:59
also I found the argparse was not working since I deleted the main(), so I fixed that
1:59
but I really confused with the error
achilleas
1:59 PM
it says 3 given because the first argument is self
1:59
Since it’s being called as an object method
rickskyy
2:02 PM
you are my savior, just forgot about it, my fault)
achilleas
2:02 PM
I assume the test script is using the checked out repository, which is your branch
2:02
and from the term you’re importing the old version?
2:02
:slightly_smiling_face:
2:02
Glad to be of service
rickskyy
2:04 PM
I thought I was using checkout repository
2:05
I mean it is a good question because I do not know what version I call in terminal and what happens inside (edited)
achilleas
2:07 PM
you can use

import odml
odml.__file__

2:07
So see where it’s being imported from
rickskyy
2:10 PM
i got this i think it ok
'/usr/local/lib/python2.7/dist-packages/odML-1.3.dev0-py2.7.egg/odml/__init__.pyc'
achilleas
2:12 PM
well that’s your system-wide installed odml package, which means if you switch branches or change things in your code directory, you wont be using the latest changes from the term
rickskyy
2:12 PM
so it takes the version where .write_file was not an object method?
ok
2:13
how could  Ichange that
achilleas
2:13 PM
no I think it takes a version where .write_file didn’t take a format argument
rickskyy
2:13 PM
wondering why my manual tests were passing before) (edited)
achilleas
2:14 PM
You can uninstall the system-wide odml pip uninstall odml and then from the code directory do python setup.py develop
2:16
Which puts a symlink in the site-packages and so whenever you import, the system-wide version becomes whatever you have in your code repo
rickskyy
2:17 PM
thank you work out nice
achilleas
2:17 PM
:thumbsup:
thumbsup:
rickskyy
2:19 PM
:blush:
dumdribille
2:40 PM
just saw the changes on the PR. will choices=list(cls._conversion_formats) just add the list of keys of the _conversion_formats dict?
rickskyy
2:40 PM
yes
2:40
i checked that
dumdribille
2:41 PM
ok, nice. :slightly_smiling_face:
2:41
and approved.
rickskyy
2:42 PM
oh i do not know if it works at python 2)
2:42
guess if travis built it it is fine
2:42
or not?
dumdribille
2:44 PM
is there a test that checks parsing from the commandline?
rickskyy
2:44 PM
no)
2:45
will write now and check
dumdribille
2:45 PM
cool, thx!
rickskyy
2:45 PM
I was actually struggling with how to test creation of folders and so on
2:47
because FormatConverter has not covered with tests at all yet
dumdribille
2:48 PM
ah, ok.
2:48
any particular difficulties? I'm just wondering if we have some similar tests in another project already I could point you to.
rickskyy
2:50 PM
before I used stringIO for testing files but how do I check creating of folders subfolders etc automatically, I should surf for some solution in the web (edited)
dumdribille
2:54 PM
hm, I don't think we have similar tests in python so far.
2:54
the only thing remotely similar would be this here, but I don't know if that is of any help to what you have in mind
2:54
https://github.com/G-Node/gin-repo/blob/master/contrib/mkdata.py
GitHub
G-Node/gin-repo
gin-repo - G-Node Infrastructure - Repository server
rickskyy
3:01 PM
it might help
3:01
thanks
3:06
@dumdribille read all newly created todos, everything is well described, really no questions)
dumdribille
3:08 PM
ok, cool! I tried to be as descriptive as possible.
rickskyy
3:09 PM
You did a great job towards detalization)
dumdribille
3:09 PM
:wink:
3:10
I will be on vacation until 28.08
3:10
I will be available on and off tomorrow as the wlan on the train permits
3:11
and will probably look in on slack and email until wednesday next week, but then I'm offline
3:11
if any questions come up I try to answer everything until wednesday
rickskyy
3:12 PM
ok, I think I will make some progress in those directions so will see if I would have any
3:12
how about others?
dumdribille
3:12 PM
as far as I know, Jan and Achilleas will be still here until friday next week
rickskyy
3:13 PM
ok good
achilleas
3:13 PM
nods
achilleas
3:13 PM
yeah, I’m here until 18
rickskyy
3:13 PM
Wondering how you make nice references
rickskyy
3:13 PM
rickskyy
3:13 PM
like this
3:14
first page of google have not provided me with the answer on several requests
3:14
:sweat_smile:
achilleas
3:14 PM
The thing you see on the second screenshot happens automatically when you put the #number in the comment
rickskyy
3:15 PM
ok I did it on first
3:15
and nothing happened
3:15
I want some magic)
achilleas
3:15 PM
can you link the issue where you made the comment?
rickskyy
3:15 PM
https://github.com/G-Node/python-odml/pull/145
GitHub
Add Property.value_origin and Property.reference attrs by rickskyy · Pull Request #145 · G-Node/python-odml
This PR includes: Merge of python-odml/master and python-odml/dev-odml-rdf branches. Add Property.value_origin and Property.reference attributes to the rdf converter. Relevant changes to ontology.
achilleas
3:16 PM
right, so if you go to #141 you’ll see it says you referenced issue #141 from #145
rickskyy
3:16 PM
oh i got it
3:17
thanks
3:18
it was easy)))))
achilleas
3:18 PM
if you want to reference stuff in another repository, you can do stuff like user/repository#number (e.g., G-Node/odml-ui#10)
rickskyy
3:18 PM
cool
achilleas
3:19 PM
and if you reference an issue in a pull request with one of a few special keywords (stuff like fixes #10 or closes #20) the issue will be automatically closed when the PR is merged
rickskyy
3:21 PM
that's nice feature


11.08.2017

rickskyy
11:39 AM

@prefix odml: <https://g-node.org/projects/odml-rdf#> .

@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .

@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

@prefix xml: <http://www.w3.org/XML/1998/namespace> .

@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

File used for queries
rickskyy
11:39 AM

<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet type="text/xsl" href="odmlTerms.xsl"?>

<?xml-stylesheet type="text/xsl" href="odml.xsl"?>

<odML version="1.1">

  <section>

rickskyy
11:39 AM

from rdflib import Graph, Namespace, RDF

from rdflib.plugins.sparql import prepareQuery

​

g = Graph()

g.parse(

rickskyy
11:41 AM

q1

Doc: https://g-node.org/projects/odml-rdf#cd24b60f-1d5e-4040-9881-5e5a597baef7, Sec: https://g-node.org/projects/odml-rdf#4620a3bf-3316-4a00-9fa0-206aaf520d4a,

Prop: https://g-node.org/projects/odml-rdf#902f9acf-f13c-4b29-ae3b-a9463e480752, Bag: https://g-node.org/projects/odml-rdf#3aab5e4d-3be5-4ffa-92c2-a08ba2ab0393

q2

Doc: https://g-node.org/projects/odml-rdf#cd24b60f-1d5e-4040-9881-5e5a597baef7, Sec: https://g-node.org/projects/odml-rdf#4620a3bf-3316-4a00-9fa0-206aaf520d4a,

Here is the result
rickskyy
11:43 AM
commented on query.py
@jgrewe Please check the queries you mentioned in https://github.com/G-Node/python-odml/issues/142
rickskyy
11:50 AM
The result is just URIRefs of entities, I guess when you mentioned select d.* from dataset d ... you wanted all info about the doc, but in this case I just wanted to try sparql and how to work with it. Please tell what you think.
rickskyy
3:05 PM
Maybe you have more docs like this, so I can add them and see the results on merged graph
rickskyy
3:10 PM
@dumdribille could I close approved by you PRs so I would not struggle with merging? Because I have another one with this sparql example one.
achilleas
3:11 PM
Unfortunately, I doubt you'll get a response from Michi any time soon @rickskyy
3:11
WAIT WHAT
dumdribille
3:11 PM
@achilleas got 10 more min of wifi!
achilleas
3:11 PM
He's TYPING
rickskyy
3:11 PM
yeah)
dumdribille
3:11 PM
then vienna .D
achilleas
3:11 PM
well, thanks for making me look all WRONG
dumdribille
3:11 PM
was a fluke, wifi is coming and goi
rickskyy
3:11 PM
:smile:
dumdribille
3:11 PM
hah, that was nice
achilleas
3:12 PM
lol
3:12
indeed
3:12
ok then I'll go away so as to not add any more noise and let you guys do your thang
dumdribille
3:12 PM
@rickskyy regarding the PR: really want @jgrewe to also sign off on these so we know he is in the loop...
rickskyy
3:13 PM
ok fine, I will add PR from new branch then
3:13
what about reviewing in the future?
dumdribille
3:13 PM
I know it`s a bit tedious but that ensures that people all over are on the same page :wink:
rickskyy
3:14 PM
during next week
dumdribille
3:14 PM
I'm also sitting on tons of PRs :stuck_out_tongue:
rickskyy
3:14 PM
lol
3:14
nice vacation)
dumdribille
3:14 PM
we'll 5 by now actually, lets not go overboard
3:15
I will be able to read PRs until Wednesday, just a bit less frequent
rickskyy
3:15 PM
ok, I got the point, enjoy your trip)
dumdribille
3:15 PM
after wednesday i'm out of it and jan and you can close PRs when they are reviewed, I will catch up on the closed PRs when I'm back :wink: (edited)
rickskyy
3:16 PM
good)
dumdribille
3:16 PM
ok, need to sign off now and pack up mah stuff
3:17
I'll shortly check back this evening
jgrewe
3:55 PM
@rickskyy, @achilleas  I just tried to catch up with the odml pull requests… I am kind of afraid we aready have a mess at hand…
3:56
for example the #145 contains stuff that should go to master, right?
3:56
The handling of the core stuff
achilleas
3:56 PM
e.g., value origin
3:56
yeah
3:57
But we could cherry pick later, if they're independent enough
jgrewe
3:57 PM
So either I merge this one and we cherry pick to master but this will be terrible when ref needs to be merged into master
achilleas
3:57 PM
blergh
jgrewe
3:57 PM
ups, rdf, not ref
achilleas
3:59 PM
yeah I see your point
rickskyy
3:59 PM
I think I misunderstood
3:59
and make all this bad
achilleas
3:59 PM
anything else you've noticed that makes things messy? I haven't been paying attention to odml today and I'm way behind on the rdf progress
jgrewe
3:59 PM
rather, methinls we should have the core parts going to master, rebase rdf against master
rickskyy
3:59 PM
oh wait
4:00
master is already contains core values
4:00
changes
4:00
everything is ok
4:00
I mean there are some commits from master but that is what was indented
jgrewe
4:00 PM
ok, hm, let’s still think for a bit
rickskyy
4:00 PM
I made as @dumdribille said
4:01
i find the message
jgrewe
4:01 PM
@rickskyy do not worry
rickskyy
4:02 PM
So the first step would be to implement and merge this into python-odml master, then import into the rdf-dev branch, add this field to the ontology and then include it into the RDF export as well
4:02
@dumdribille closed PR
4:02
to master
jgrewe
4:02 PM
Cleanest way probably is to first rebase rdf against master
rickskyy
4:02 PM
https://github.com/G-Node/python-odml/pull/143
GitHub
Add value_origin to the Property entity by rickskyy · Pull Request #143 · G-Node/python-odml
Implementation of the Property.value_origin due to #130
jgrewe
4:04 PM
tricky things are the merges from master into rdf
rickskyy
4:04 PM
will they matter in the future?
jgrewe
4:04 PM
when we want to merge rdf into master, maybe they cause trouble
4:09
just tried to rebase it and failed :disappointed:
rickskyy
4:09 PM
I think it's ok, because there were small changes, so even if it would be some conflicts , it can be easilt resolved, but I up to your suggestions
jgrewe
4:09 PM
let’s see how bad it is
4:13
ok, not too bad
jgrewe
4:22 PM
How best to proceed? @achilleas would like to have your opinion on this:
In short: Situation now is a bit messy, lots of merge commits in the repo, some conflicts as well.
1. I would force push the rebased rdf branch
2. @rickskyy would need to pull it and rebase his topic branches onto the updated rdf
3. from branch rickskyy:dev-value (pull request 145) only the last 4 commits should be cherry picked into a new topic branch
4. same may apply to pull request 144… ups, this ist basically equivalent of the g-node:dev-odml-rdf…
4:22
bad idea, need to clean point 4 first…
achilleas
4:47 PM
yeah, I don't think it's that bad to rebase and force push dev branches. In the worst case, if you don't like forcing it, we could rebase and push as a new branch rdf...-rebased or whatever, to keep things clean-ish
jgrewe
5:26 PM
alternative approach: I cherry pick the stuff from the development branches …
5:26
but kind fo risky to miss some essential commits :slightly_smiling_face:
achilleas
5:31 PM
yeah


12.08.2017

jgrewe
12:35 PM
I rebased the rdf branch against master and pushed it to g-node as rdf_converter. @rickskyy please confirm that it is correct. In particular the following file:
- test_rdf_writer: [rdf] remove id form hub removes parts of the test line24 ff, in [rdf] adding value_origin attr to rdf converter these lines are again present… and it fails on travis :slightly_smiling_face: (edited)
rickskyy
12:37 PM
Ok, will check now
jgrewe
12:39 PM
Thanks!
for the following let us try to keep it free of merge commits that introduce changes from master.
The workflow could be something like:
1: always work o topic branches
2: rebase the rdf branch if there are changes in master, that need to be taken over. This should keep ther merge to master clean
rickskyy
12:40 PM
Good, I understand, thank you)
jgrewe
12:44 PM
do you understand the traiv fail?
rickskyy
12:44 PM
Ok where I can see the changes @jgrewe ?
jgrewe
12:44 PM
https://travis-ci.org/G-Node/python-odml/jobs/263791607
12:44
this is the travis error log (edited)
12:45
https://github.com/G-Node/python-odml/tree/rdf_converter
GitHub
G-Node/python-odml
python-odml - odML libraries
12:45
this is the new branch, should include all your commits :slightly_smiling_face:
rickskyy
12:46 PM
Oh it is named as my old branch so I thought it is smth strange
jgrewe
12:46 PM
haha
12:46
bad luck
12:47
a convenient name
rickskyy
12:48 PM
yeah it looks like we forgot smth in id section
12:48
id part*
jgrewe
12:50 PM
ups, did I forget a commit?
rickskyy
12:59 PM
i do not know check if you forgot
12:59
but there is missing id=None in Property constructor
1:00
that is it, I run tests locally and everything is ok)
jgrewe
1:00 PM
you’r right, fixes everything
1:00
nice
1:01
funny error message
rickskyy
1:01 PM
so should I check all commits missing?
1:01
if missing
jgrewe
1:01 PM
yeah, would be good, in particular the test_rdf_writer which had a conflict
1:01
the other “should” be fine
rickskyy
1:02 PM
so would you add new commit, or maybe I will add one with all fixes later
jgrewe
1:02 PM
I will introduce the id fix now
rickskyy
1:02 PM
with all fixes if needed*
1:03
I see you added some commits from open prs too
jgrewe
1:04 PM
yes, all of them I hope
rickskyy
1:04 PM
except new one
1:04
about sparql
jgrewe
1:04 PM
ah, yes, they are not in yet
1:05
so 144 and 145 it was
rickskyy
1:06 PM
ok, will just bring second screen from another room, and start reviewing:smile:
jgrewe
1:08 PM
haha, will look impressive on your desk :slightly_smiling_face: Just pushed the id fix
1:12
I will be offline for a while but will be back later. see you
rickskyy
1:12 PM
fine
rickskyy
1:25 PM
test_rdf_writer is ok
1:29
overall it looks like you did a great job and everything merged perfectly. Although somehow PEP8 blank lines in the end of almost all edited files are removed, but that is totally fine)
jgrewe
2:27 PM
hehe, cool, I can live with this :slightly_smiling_face:
Thanks a lot. I will then close your prs, and we can decide to work against rdf_converter from now on or I will force push the “old” odml_rdf_dev branch. What do you think?
rickskyy
2:29 PM
I vote for force push I like the previous name better)
2:29
So I will reopen the sparql stuff in the updated brunch
achilleas
2:30 PM
I see y’all are having fun
jgrewe
2:30 PM
ok, fine with me :slightly_smiling_face:
2:30
indeed
achilleas
2:30 PM
branches sorted?
rickskyy
2:31 PM
Yeap
achilleas
2:31 PM
neato
rickskyy
2:31 PM
Happy Saturday:smile:
achilleas
2:31 PM
woo \o/
jgrewe
2:32 PM
it always makes me nervous to force push to g-node, why?
rickskyy
2:33 PM
You can do it)
achilleas
2:33 PM
I don’t know but it should so you’re ok
2:33
I mean, it should make you nervous
2:33
that way you’re more likely to pay attention to what you’re doing :smile:
jgrewe
2:34 PM
yeah, you’r right, works for me, I guess
2:35
https://github.com/G-Node/python-odml/network
GitHub
G-Node/python-odml
python-odml - odML libraries
2:36
nice and clean :slightly_smiling_face:
rickskyy
2:36 PM
:blush:


17.08.2017
rickskyy
10:13 AM
Good morning everyone. How are you doing? Want to ask you for advice. I prepared a PR with RDF-odml converter and branched it from last merged commit from G-Node/dev-odml-rdf. While developing I reused the newly merged to master branch ODMLReader, used some functions from it (to not writing same thing again) and extended it with RDF parser. Also I will rewrite RDFWriter class to make it compatible with the generic converter, so the overall picture will be nice. The question is how should I deal with changed odmlparser.py. Should I just add it dev-odml-rdf and then in the future we resolve changes while merging? Or we need to rebase dev-odml-rdf onto changes in master now. I saw there also some stuff that need to be resolved.
jgrewe
2:55 PM
Hi rickskyy sorry for being slow with replies. It's been a busy week so far...
Regarding your question: I just rebased and force pushed
2:57
hope that helps
rickskyy
3:05 PM
great thanks)


29.08.2017
dumdribille
3:17 PM
hi @rickskyy!
rickskyy
3:17 PM
hi
dumdribille
3:17 PM
I'm back and started reading through the pull requests.
3:17
how were the last two weeks?
rickskyy
3:19 PM
So I was on a short vacation and then traveled to Germany.
dumdribille
3:19 PM
cool
3:19
the hotel for friday seems to be booked
3:19
but I need to find out the details still
3:19
I'll let you know tomorrow. :wink:
rickskyy
3:20 PM
Yeah, I received much info and help)
3:21
I arrive at Munich at 9.40 pm on Friday.
dumdribille
3:21 PM
oh, I thought it was a bit earlier.
3:21
will you stay on saturday?
rickskyy
3:27 PM
Unfortunately, it it the earliest time we could make it
3:28
Yeah we have a bus to Poland at 8 pm on Saturday
dumdribille
3:30 PM
ah, ok. do you want to hack a bit saturday before noon and then go for a tour of the city? Or do you have different plans so far?
rickskyy
3:38 PM
For now we do not have any special plans, so we are welcome any suggestions and propositions
dumdribille
3:39 PM
Ok cool, then I will try to come up with sthg until Thursday. :slightly_smiling_face:
3:39
How's your trip so far?
3:39
Are you already in Berlin?
rickskyy
3:42 PM
Yeah, we a great, have already explored the city a little bit. Now living and listening to some lectures in Berlin Buch Campus. Have really packed with events timeline (from 9-6) (edited)
dumdribille
3:44 PM
That sounds really neat! :slightly_smiling_face: Then I'll leave you to it for now. :wink:
3:44
I'll let you know once I have more infos/ideas for saturday!
rickskyy
3:44 PM
great thank you)


31.08.2017
dumdribille
Hi @rickskyy
Ok, now I have a better idea about your visit. sucks, that the ibis nord did not work out, it would have been better connected than the ibis schwabing one, but what can you do...
So if I got it correctly, you arrive on Friday evening (21:40) by bus at the Munich ZOB at Hackerbrücke? And you will leave from by Bus on Saturday at 20:00?
If you have Internet on your phone here in Germany I can really suggest the MVG Fahrgastinfo App for finding your way around the city by public transport.
I think I won't join on Friday evening, if that's ok. If you want to go for a quick drink before you head for your hotel, I can recommend the 'Parkcafe' at Sophienstraße 7, 80333 München, since it is quite close to both ZOB bus station and the central train station.
For Saturday, would you be ok with some light hacking at the university where we have internet, (maybe between 10 and 14?), then go for a late lunch and go for a tour of the city in the afternoon? I can give you a quick tour to the sights in the inner city if you want to. Unfortunately the weather does not look too good; I'll try to figure out some alternative plans with respect to bad weather as well...
If you are fine with that, I would suggest we meet at 10:00 at the U6 Klinikum Grosshadern Subway station, which is relatively close to the university.
Regarding public transport tickets: If you guys stay together the whole time, I think it would be cheapest if you buy a single trip ticket (1 zone = 2.80€) each on friday and one Group Day Ticket on (Inner Zone = 12.60€) which is valid for both of you. If you want to split up on Saturday, you can get two Day tickets (inner district = 6.60€). you can find out more about the tickets here: http://www.mvv-muenchen.de/en/tickets-fares/tickets/index.html
Regarding your luggage: I think you can either leave it at your hotel, but since it is quite inconveniently located for getting it later in the day, you could also leave it at the central train station. They have a great many of them and I guess it would be more convenient to fetch, since it is quite close to the ZOB bus station.
If you need any other information, directions etc. or if you want to do different things, just let me know! :slightly_smiling_face:
mvv-muenchen.de
Tickets (7kB)
rickskyy
5:31 PM
Hi @dumdribille,
rickskyy
5:53 PM
Thank you for the information and the plan. The meeting at 10.00 am is good for us. However, I did not fully understand the meeting place. You mentioned the U6 Klinikum Grosshadern - seems to me it is the name of the subway line and not the station. Did you mean this station Universität, 80799 München?, just to make sure.
We are going to be together all the time, thanks for mentioning the prices.
We think leaving the bags on the station is better option for us, so we will go to the station before the meeting at 10 am, but we will be on time.
Looking forward for the meeting :smiley:
5:54
The arrival and departure dates are correct.

01.09.2017
dumdribille 11:06 AM
Ok, its settled then, nice! :)
11:08
U6 is the name of the subway line and klinikum grosshadern is the name of the station i'd suggest we meet. Its at the edge of munich, since the university is located slightly outside of munich. ;)
rickskyy
7:39 PM
Oh, I got it. I just googled lmu location and omitted the fact that institute can be located in the other place


04.09.2017
rickskyy
11:34 AM
I am finally back) It was a tough journey. We were late for our train from poland to ukraine by only 5 min because of people were running a marathon and the road was closed. Overall the bus was late for almost 2 hours but the running guys killed our hope at the last moment. Nevertheless, we managed to get back to Kyiv through Lviv :slightly_smiling_face: (edited)
dumdribille
11:51 AM
aaaah that sucks...
11:52
sorry to hear it! I hope you didn't have to buy new tickets for the train. :confused:
rickskyy
12:09 PM
it was cheap and also I returned some money from the one we missed, not a big deal - overall lose was like a good beer in Munich)
dumdribille
12:11 PM
ah ok, glad to hear it. :sli


06.09.2017
rickskyy
2:16 PM
@dumdribille @achilleas want to ask you a git related question.
I have just rebased some feature branches (tests, sub-sec) onto the merged commits (from rdf-odml) to have a cleaner history. Since tests and sub-sec were not merged yet by making my changes public I overwrote my previously commited files and comments appeared above commits. Though it maybe do not makes much difference, if I do not change the content of new commits, I want to make clear that I chose the right way to do the process in the future.
2:17
See Michael have just merged tests while I was writing this :sweat_smile:
achilleas
2:18 PM
Generally speaking, as long as the branches aren't merged and especially if they're on your personal fork, you can rewrite history as much as you want :slightly_smiling_face:
2:19
You're correct in thinking that, since there was an open pull request with those branches, you didn't want to change the commit messages
2:20
If I understand what you're describing correctly, that's basically how we do it as well. If a branch associated with an open pull request needs rebasing, we try not to change the order and messages of the new commits, so that it appears as if it was written after the latest merge.
2:21
Some people like to reorder commits to bundle them together so that they make more sense, others like to squash them to make history shorter. I don't think any of us have specific preferences for these cases.
rickskyy
2:31 PM
Understood, thanks
rickskyy
5:57 PM
@dumdribille added loading of subclass mappings via yaml in last commits. Check please if it looks appropriate, so I would add all subclasses from http://portal.g-node.org/odml/terminologies/v1.0/terminologies.xml
dumdribille
5:59 PM
was just checking it, it looks fine.
6:00
should I merge the PR now or do you want to add the other classes to this PR?
rickskyy
6:01 PM
actually I just wanted to extend this yaml file, if it is in the high priority
dumdribille
6:01 PM
sounds good, then I'll wait until you've had the chance to add it. :wink:


07.09.2017

rickskyy
11:03 AM
@dumdribille want to set up my work plan for next days and prioritize the tasks. Here is how I see the whole picture.
0) Running complex queries for multiple files (probably all gin repo) to compare efficiency on different rdf libraries. #167
1) Setup Jupyter Notebook #117 (Document examples of usage of implemented classes)
2) Tests + subclasses implementation for RDFReader
3) Somehow merge FormatConverter with existing tools and rename it...
4) Add subclasses to ontology after all is approved to be efficient. (edited)
11:05
All in all, everything goes to #167 query efficiency comparison, am I right?
dumdribille
11:09 AM
sounds very good!
11:10
and basically #167 should give us a good idea how well our design works so it indeed boils down to that issue. :slightly_smiling_face:
rickskyy
11:11 AM
Do you think I should focus on queries first?
dumdribille
11:13 AM
I think that would be the most important result for now, so I'd go for it first.
11:14
I think Jan will be back from vacation next week.
11:15
But we are going to a conference on Tuesday, so we'll be available via slack, but not via hangout.
11:15
I don't know Jans timetable yet, but would you have time for a hangout on Monday?
rickskyy
11:16 AM
I think I will, but only after 2.30 pm my time - 1.30 yours
dumdribille
11:17 AM
ok, cool. so if Jan is available, that would be nice to have some facetime again, now that everyone is back.
rickskyy
11:17 AM
:blush:
dumdribille
11:19 AM
we'll try to figure it out until tomorrow.


08.09.2017

dumdribille
3:17 PM
huhu
3:18
bist du montag wieder in der arbeit? und würdest du ein meeting mit Yaroslav machen wollen? wir sind ja ab Dienstag dann schon nach Göttingen unterwegs.
jgrewe
3:19 PM
Hey, jo können wir machen. Gibt es denn auch ein gnode treffen ?
3:20
Habe noch keine Lust wieder zu arbeiten :wink:
dumdribille
3:20 PM
ich denk schon; Yaroslav hat gemeint, er hätte gegen 13:30 unserer timezone ein zeitfenster - der ist ja jetzt wieder unimäßig unterwegs.
3:21
und bzgl arbeit kann ich gut verstehen, ging mir genauso nach der woche bergsteigen. :slightly_smiling_face:
jgrewe
3:22 PM
Ok, dann lass uns das festhalten
dumdribille
3:22 PM
cool, dann post ich das für Yaroslav im odml channel. :slightly_smiling_face:
3:23
wollen wir da irgendwas im speziellen besprechen?
3:23
von meiner seite her wart ich noch auf die resultate der queries.
jgrewe
3:24 PM
Oh und dafür sollte er noch mehr Dateien haben, oder?
3:24
Ich persönlich brauche ein Update
dumdribille
3:25 PM
mehr daten ist immer gut! aber als er hier war haben wir besprochen, dass er zumindest mal alle files die er zur zeit zur verfügung hat in einen graphen laden und dort die queries absetzen soll.
3:25
dann sehen wir zumindest mal obs gar nicht funktioniert. :wink:
3:26
dann werd ich ihn bitten, ob er uns am montag eine kleine zusammenfassung der letzten drei wochen geben kann, damit wir beide sicher sind, dass wir nichts verpasst haben.
3:26
aber prinzipiell schaut es von der features die bisher implementiert sind ja schon ganz gut aus im vergleich mit dem was wir in das proposal reingeschrieben haben.
3:27
haben wir für uns einen zeitplan für dieses projekt? wollen wir schauen, dass wir bis ende september fertig sind?
3:27
da muss ich ohnehin auch noch thomas fragen, wie der vertrag dann tatsächlich* erledigt wird. (edited)
jgrewe
3:28 PM
Klingt gut. Müssen auch mal schauen, ob der schon Geld gesehen hat.
dumdribille
3:28 PM
genau
3:28
ich glaub er kriegt erst geld wenn wir sagen, dass der vertragsinhalt geliefert wurde.
jgrewe
3:29 PM
Ok, dann wird es Zeit, dass wir uns drum kümmern
dumdribille
3:30 PM
dann erkundige ich mich mal bis montag bei thomas
jgrewe
3:30 PM
Cool
dumdribille
3:30 PM
sehr fein, dann post ich mal die zusammenfassung für yaroslav :wink:
dumdribille
3:31 PM
@rickskyy jan and I just had a little chat regarding monday, and it would be cool to have a hangout on monday at 13:30 our time if that still fits your schedule.
3:33
also, if you could give us a small recap of the implemented features of the last three weeks, that would be awesome, then Jan and I are sure, that we have not missed anything that happened during our respective vacation times. :slightly_smiling_face:
rickskyy
4:16 PM
Great, it fits to me, I will prepare the recap)
dumdribille
4:19 PM
awesome, thx!


11.09.2017
dumdribille
12:30 PM
huhu
12:31
Thomas hat gemeint, sobald wir ihm sagen, dass die arbeit von Yaroslav erledigt ist, weist er an, dass das geld überwiesen wird. dann dauerts noch etwa 2 wochen bis das geld tatsächlich im ausland ankommt, weils durch einige prüfungen durch muss.
12:31
außerdem wollte Thomas noch anmerken, dass er gerne einen server hätte, auf dem ein SPARQL endpoint auf die exportierten daten läuft, damit man das auch direkt testen kann.
12:32
und er hat gemeint, wenn nötig und falls Yaroslav das möchte, können wir noch einen weiteren monatsvertrag dranhängen.
12:33
denkst du wir sollen das alles heute schon mit Yaroslav ansprechen oder erst nächste woche und bis dahin nochmal einen detaillierteren plan für das letzte monat machen?
dumdribille
1:25 PM
huhu nochmal
1:26
also Thomas meint, wir sollten alles auf einmal auszahlen, nachdem wir im ersten drittel nicht begonnen haben, das geld zu splitten. jetzt wär es inkonsistent 2/3 auszuzahlen und dann nochmal 1/3.
jgrewe
1:27 PM
ok, von mir aus
1:28
dann muessen wir nur aufpassen, dass wir den cut auch bei Zeiten machen
1:28
und ihn nicht zu lange haengen lassen
dumdribille
1:28 PM
indeed
1:29
wir können ja schauen, dass wir die wichtigsten punkte bis in zwei wochen fertig haben, die zahlung anweisen und polishing noch 1-2 wochen zu machen, dann sollte er das geld in3-4 wochen haben.
jgrewe
1:31 PM
jupp, klingt gut
dumdribille
1:32 PM
calling via hangout
rickskyy
1:33 PM
https://docs.google.com/document/d/1BJy1nhzp9mmAHO-0Jn_ZyRnng9pYZNCbs0IKNvpnQFM/edit#
dumdribille
1:35 PM
sry, microphone troubles
rickskyy
1:44 PM
http://librdf.org/
1:46
https://github.com/RDFLib/rdflib-sqlalchemy/blob/develop/README.md
GitHub
RDFLib/rdflib-sqlalchemy
rdflib-sqlalchemy - RDFLib store using SQLAlchemy dbapi as back-end
jgrewe
1:52 PM
https://www.bioontology.org/wiki/images/6/6a/Triple_Stores.pdf
1:52
https://www.w3.org/wiki/LargeTripleStores
rickskyy
2:05 PM
https://docs.google.com/document/d/1BJy1nhzp9mmAHO-0Jn_ZyRnng9pYZNCbs0IKNvpnQFM/edit?usp=sharing


18.09.2017
rickskyy
9:33 AM
Good morning everyone,
Just pushed first version of fuzzy finder prototype.
Have some questions.
1) I have created a jupyter documentation for implemented RDF classes. Should I create a PR for the review or just send it here?
2) Also I wanted to clarify the day of the meeting. Did we plan it for tomorrow or today? :sweat_smile: (edited)
dumdribille
1:28 PM
I think we said tuesday again, but I might remember incorrectly. :slightly_smiling_face:
1:29
thx for the fuzzy finder, will check it later during the day!
1:30
ad 1) with respect to documentation I'm fine either way, lets see which @jgrewe prefers.


19.09.2017
rickskyy
9:51 AM
Hello @dumdribille  @jgrewe , is it possible to reschedule the meeting to 5pm my time 4pm yours today?
jgrewe
9:51 AM
No problem from my side. See you later
dumdribille
10:34 AM
no problem here either, until 4/5 then. :wink:
rickskyy
4:02 PM
RDF tools.ipynb
Binary Click to download
dumdribille
4:08 PM
calling :slightly_smiling_face:
jgrewe
4:08 PM
ups, second
rickskyy
4:22 PM
1) doc(author:Name) sec(type:sec1) prop1(...) (edited)
4:23
2) doc(..) [sec(...)  prop1(..) prop2(..)] (edited)
4:24
3) doc sec prop1 prop2 (edited)
4:25
4) doc sec1 sec2 prop1 prop2 (edited)
4:26
5) d [s1 p1 p2] [s2 p3 p4] (edited)
jgrewe
4:27 PM
ncbi
dumdribille
4:27 PM
https://www.ncbi.nlm.nih.gov/books/NBK3837/
NCBI Bookshelf
Entrez Help
Entrez is NCBI’s primary text search and retrieval system that integrates the PubMed database of biomedical literature with 38 other literature and molecular databases including DNA and protein sequence, structure, gene, genome, genetic variation and gene expression. This document is an overview of the Entrez databases, with general information on searching and displaying data. More detailed help is available for the individual Entrez databases in the NCBI Help Manual sections on the NCBI bookshelf.
jgrewe
4:34 PM
Arthur[sec.name] AND Human[prop.value] (edited)
rickskyy
4:38 PM
select sec.name where doc(..) sec(type:sometype) prop(..) prop(..)
jgrewe
4:40 PM
select sec.name where human and crew
4:41
ups, hangout crashed


28.09.2017
rickskyy 10:53 AM
hi @U1FMV8NLT @dumdribille, working with benchmarking for fuzzy finder. Now I use SQLAlchemy plugin for rdflib with MySQL db as triple store, because loading over 200 files (drosophila files from gin repo) in memory every time is quite time-consuming. How do you like me to organize jupyter documentation with the benchmarking so you can manually test queries yourself.
1) The straightforward solution is just add gin ttl files (5 Mb) to the doc folder and load the graph every time, it takes from 1 to 2 minutes on average to load 100k triples.
2) More complex way is set up the db in the cloud somewhere so everyone can connect to it and test.
The first way is not too bad also since I can load the graph only once and work with it in memory for some time without closing, so here jupyter becomes really useful.
In any way I plan to finish all the work by tomorrow and present the results to you. Also we can set up a hangout either tomorrow or during the next week. (edited)
rickskyy 11:11 AM
Some edits, just tried running queries on SQL db and noticed that the difference between in memory tests and db tests is too huge, smth like quering the db is 60 times slower :sweat_smile: than the same query in memory (I do not count the graph loading time). Gave up using db for now.
Also I looked for some storage services yesterday and find out some rankings https://db-engines.com/en/ranking/rdf+store. The first one is commercial so I do not think it would work for us. Jena is only compatible with Java but it looks impressive with great documentation and so on. In addition it is open source. Also I want to try it and see the difference in speed of queries compare to python rdflib. Have not looked to virtuoso yet.


04.10.2017
jgrewe 8:55 AM
@rickskyy sorry for the long delay. Due to familiy issues I will be kind of knocked out this week. I will be available again next week…


06.10.2017
rickskyy 1:15 PM
That's ok, no problems.
rickskyy 1:47 PM
Just to not forget, while writing some tests, I ran into a bug with odml.load() function. If I load odml document, for example one generated by `doc/example_odMLs/odml_ex_1_generator.py` and assign float number to one of `value` attributes it saves only integer part. The same thing happens for multiple values.
I think there is a problem with `from_csv()` function from `xmlparser.py` in part
   `stream = StringIO(value_string)`
   `stream.seek(0)`
   `reader = csv.reader(stream, dialect="excel")`
or I am missing smth and this has been already solved in the newer version. (edited)


09.10.2017
dumdribille 9:31 AM
hi guys*, we are back from japan! was quite a journey both workwise and travel experience... I'll read up on the issues and PRs until the evening! (edited)
achilleas 10:04 AM
Such courage
10:04
Reading PRs on the first day back
rickskyy 12:22 PM
@dumdribille Great you back.
@dumdribille @jgrewe some review tips. In `FuzzyFinder` class there are implemented 2 main functions `FuzzyFinder.find()` and `FuzzyFinder.find_fuzzy()`. The second is more fuzzy than first and I assume it's more relevant to requirements we were discussing earlier. Basically, `FuzzyFinder.find_fuzzy()` is an extension to the previous one, but I left first find() to see your comments.
You can test them in jupyter notebook on part of drosophila database which consist of 17k triples. I added this ttl files just for testing purposes and to show difference of speed between queries with various complexity. Definitely they might not be added to python-odml repo and there are ways to load them from external service. (edited)
12:24
Also thank you very much for the money you sent me in the end of September
dumdribille 5:30 PM
@U642BPMRD awesome, I'm happy the payment worked w/o problems, well deserved as I might add. :wink:
rickskyy 5:30 PM
Thanks)
dumdribille 5:30 PM
and I was too optimistic on my PR reading skills, couple of meetings derailed me, so I'll probably will finish reading them tomorrow. I hope you don't mind.
rickskyy 5:31 PM
Of course not :blush:
dumdribille 5:34 PM
I also talked with Roman Moucek in Japan regarding the Java/Hadoop project Zinovi was interested in. It seems the guy that was in charge (Petr Ježek) is currently for another project in the states.
5:36
Since Roman was just the backup mentor on the project, he* could not tell me whether Petr is currently planning to follow up on the idea. (edited)
new messages
rickskyy 6:45 PM
Thank you for the information.


10.10.2017
dumdribille 11:27 AM
@U642BPMRD just saw, that the two open PRs overlap to some degree, but are also somewhat different. Should I simply close the jupyter nb specific PR and we deal just with the Fuzzy finder PR?
rickskyy 12:01 PM
Yes, jupyter specific pr should be closed
dumdribille 12:12 PM
ok, closing now. :wink:
dumdribille 1:21 PM
@rickskyy @jgrewe just read through the PR, which provides quite a lot of really cool features, thx again! The PR is really quite large. I added a couple of review comments regarding the jupyter notebook which could be addressed right away. but there are two mayor points which @rickskyy already hinted in the chat above, and I'm not sure how to best address these.
1:24
1) Currently the PR contains tons of actual data as ttl files which we probably do not want to keep in the main repository. Therefore we probably won't merge the PR as is right now. The whole thing is useful for benchmarking nonetheless. Maybe the current comments I added can be addressed and after they have been resolved, we put the current PR into its own benchmarking branch? And once we have this branch, remove the tons of ttl files, add two or three short example ttl files, rewrite the jupyter notebook towards these files and also create proper tests with them as a basis?
Or just rename the current notebook, but rename it to "benchmark sthg sthg" and add an additional one with the reduced example ttl files.* (edited)
dumdribille 1:42 PM
2) Thx for the fuzzy finder implementations! As mentioned above, there are two different implementations. If I got it right, the `FuzzyFinder.find` returns more exact matches, since the user specifies, that the query should specifically for property and section values. The `FuzzyFinder.find_fuzzy` iterates through combinations of propery, section and the provided values. In principle I like both approaches, I'll post some of the minor points in the PR review for more comments.
The broader issue I currently have is, that with the current example files I honestly find it hard to evaluate the results and tell you if I like it from a users perspective. :wink: I guess we'll work on that when we have reduced example files.
rickskyy 2:58 PM
Responding to 2 point. Actually `find_fuzzy` returns the same thing as simple `find`. It just go through more combinations, but, nevertheless, my approach was to show/output more detailed query first in both functions and than more broad ones. You can see it in notebook but just brief example is:
if tool found some triples that matched the most specific query (e.g. all input parameters can be used together in some way) it outputs it first, than it goes to less specific until only one parameter were matched.
As you can see the output is somewhat complicated because I left lots of stuff to show the internal work of algorithms. So if we determine that we only need the most specific query result (or couple on the same level of specificity), we do need to output everything to the user. Also the user can choose whether he/she wants to see the whole output.
rickskyy 3:04 PM
I like the idea of creating new branch for benchmarking and create new notebook with more reduced examples.
@dumdribille As I understood you proposed to have 2 notebooks that would differ only with amount of example files.
Do you want to strictly separate benchmarking and general explanation in those files. So in the notebook with the reduced examples there won't be any tables with benchmarking  etc.
dumdribille 3:05 PM
yes exactly. one notebook would be for us, the other for potential users.
rickskyy 3:07 PM
got it, do we need to have rdf explanatory part with graph image in benchmarking notebook?
dumdribille 3:08 PM
no, I think this we can leave for the user specific notebook.
rickskyy 3:08 PM
cool
rickskyy 3:16 PM
@dumdribille @jgrewe Also dealing with ABC issues, I would like to discuss, if we really need those multiple parsers.
From my perspective we would only need `find_fuzzy()` or a kind of its modification. However, if you think both `find()` and `find_fuzzy()` can be valuable and not confusing, than we can leave the structure with base parser class and multiple concrete parsers.
dumdribille 3:18 PM
I leave this question to the more python versed person. :slightly_smiling_face:
jgrewe 3:18 PM
hi rickskyy, I acutally thought that we should have a find with an default argument
```find(terms, mode="fuzzy")```
(edited)
3:19
or something similar, but this can be changed later
rickskyy 3:25 PM
@jgrewe that would just merge 2 functions to one. Actually I like the proposed idea in comments by @dumdribille to rename `find` to `match`.
"Maybe rename this method to match, since find and fuzzy are already in the class name and this method is supposed to return results of exact matches of section and properties and the provided values; then it will also be better distinguishable from the second method."
Your proposition also looks nice so I would support any of this. (edited)
jgrewe 3:39 PM
am I right, that find and fuzzy_find apply two different ways for finding stuff? If this is the case I would be fine with renmaing to match and pass the desired mode of search as an argument with a default of our choice
new messages
rickskyy 3:46 PM
Yes you right, since they work with different types of our query strings.
rickskyy 3:51 PM
I do not really understand why we need mode then if we leave match() and fuzzy_find().
Do you mean that fuzzy_find is just not good name so we have only find() and use mode for specificity.
Or you would like to have 2 modes (like fuzzy and match) in find() function, so then we do not need public match() function.
jgrewe 4:01 PM
two modes that hide behind a find or match function
rickskyy 4:57 PM
Ok, understood

12.10.2017

dumdribille 4:19 PM
hey, what up? :slightly_smiling_face:
4:20
are you aware of hacktoberfest? :slightly_smiling_face:
rickskyy 4:21 PM
hello, fine, and you? No, Already googling it :smiley:
dumdribille 4:21 PM
https://hacktoberfest.digitalocean.com/
DigitalOcean
Hacktoberfest 2017 - DigitalOcean
Hacktoberfest is a month-long celebration of open source software. (134kB)
rickskyy 4:22 PM
reading it now)
4:22
I heard about it last year or some similar stuff
dumdribille 4:22 PM
if you do 4 PRs on open source projects until the end of october you get a t-shirt and some awesome stickers. :smile:
4:22
we are all taking part
4:22
just for fun
rickskyy 4:22 PM
that is cool
4:23
now thinking how can I divide last PR in 4, lol
dumdribille 4:24 PM
yeah it kinda pushed people towards atomic PRs :stuck_out_tongue:
rickskyy 4:25 PM
should I create new benchmarking branch myself to push new documentation ?
dumdribille 4:25 PM
yeah, that would be awesome!
rickskyy 4:29 PM
I mean what is the best way to make last PR great again.
I see steps in this way:
1) Rewrite documentation without benchmarking, delete those much ttl files.
2) Fix bugs all comments that you mentioned.
3) Merge the PR with FuzzyFinder and QueryCreator.
4) Create new branch from merged commits.
5) Create PR with benchmarking notebook to new branch.
6) Create PR with tests for all this stuff ( Possible 2 PRs in terms of T-Shirt for RDFReader and SPARQL staff)
7) Do smth that I forget
What do you think? (edited)
dumdribille 4:36 PM
Yeah, thats a really good plan, go for it! nothing in terms of #7 springs to mind. :wink:
rickskyy 4:38 PM
Good.
4:39
Still have some preparation for interviews and lots of work on university labs. Haskell is just racking me.
dumdribille 4:40 PM
functional ftw! wait...
rickskyy 4:40 PM
By the way, I succeed to get internship in SAP for 3 month from 8th of January to 8th of April. And also will go to on-site interview with Microsoft to Belgrad at the end of October.
dumdribille 4:41 PM
Awesome, congratualtions! \o/
rickskyy 4:41 PM
So maybe I will come to Munich during winter, also it will be cool to meet with all the odml team :smiley:
dumdribille 4:41 PM
cool, you are always welcome! :slightly_smiling_face:
rickskyy 4:42 PM
Thanks)
rickskyy 5:48 PM
Hey Michael, signing some docs for SAP internship, they ask about last employment. Am I right that I can legally say that LMU is my last employer?
dumdribille 7:48 PM
I'd say yes, but I will ask Thomas tomorrow to make sure.
rickskyy 7:51 PM
That would be great. I talked to Jan, he agreed that it would be ok to write smth like this below.
For the question: "Last Employer" I wrote "Was External contractor with LMU" (shortened the name of university here)

13.10.2017
dumdribille 9:07 AM
This you can write for sure! :slightly_smiling_face:
